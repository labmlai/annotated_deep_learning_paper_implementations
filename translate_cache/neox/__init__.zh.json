{
 "<h1>GPT-NeoX</h1>\n<p>This is a simple implementation of <a href=\"https://arxiv.org/abs/2204.06745\">Eleuther GPT-NeoX</a> for inference and fine-tuning.</p>\n<ul><li><a href=\"model.html\">Model definition</a> </li>\n<li><a href=\"tokenizer.html\">Tokenizer</a> </li>\n<li><a href=\"checkpoint.html\">Checkpoint downloading and loading helpers</a> </li>\n<li><a href=\"utils/index.html\">Utilities</a> </li>\n<li><a href=\"utils/llm_int8.html\">LLM.int8() quantization</a></li></ul>\n<h3><a href=\"samples/__init__.py\">Samples</a></h3>\n<ul><li><a href=\"samples/generate.html\">Generating text</a> </li>\n<li><a href=\"samples/finetune.html\">Fine-tuning the biases with pipeline-parallel</a> </li>\n<li><a href=\"samples/llm_int8.html\">Generating text with LLM.int8()</a></li></ul>\n<h3><a href=\"evaluation/__init__.py\">Evaluation</a></h3>\n<ul><li><a href=\"evaluation/half_precision.html\">Evaluating half precision model on a single GPU</a> </li>\n<li><a href=\"evaluation/llm_int8.html\">Evaluating LLM.int8() model</a></li></ul>\n<p><strong>Official <a href=\"https://www.eleuther.ai\">Eleuther</a> GPT-NoeX is source code is available at <a href=\"https://github.com/eleutherai/gpt-neox\">eleutherai/gpt-neox</a>.</strong></p>\n": "<h1>GPT-neox</h1>\n<p>\u8fd9\u662f Ele <a href=\"https://arxiv.org/abs/2204.06745\">uther GPT-NEOX</a> \u7684\u7b80\u5355\u5b9e\u73b0\uff0c\u7528\u4e8e\u63a8\u7406\u548c\u5fae\u8c03\u3002</p>\n<ul><li><a href=\"model.html\">\u578b\u53f7\u5b9a\u4e49</a></li>\n<li><a href=\"tokenizer.html\">\u5206\u8bcd\u5668</a></li>\n<li><a href=\"checkpoint.html\">\u68c0\u67e5\u70b9\u4e0b\u8f7d\u548c\u52a0\u8f7d\u52a9\u624b</a></li>\n<li><a href=\"utils/index.html\">\u516c\u5171\u4e8b\u4e1a</a></li>\n<li><a href=\"utils/llm_int8.html\">llm.int8 () \u91cf\u5316</a></li></ul>\n<h3><a href=\"samples/__init__.py\">\u6837\u54c1</a></h3>\n<ul><li><a href=\"samples/generate.html\">\u751f\u6210\u6587\u672c</a></li>\n<li><a href=\"samples/finetune.html\">\u4f7f\u7528\u7ba1\u9053\u5e73\u884c\u5fae\u8c03\u504f\u5dee</a></li>\n<li><a href=\"samples/llm_int8.html\">\u4f7f\u7528 llm.int8 () \u751f\u6210\u6587\u672c</a></li></ul>\n<h3><a href=\"evaluation/__init__.py\">\u8bc4\u4f30</a></h3>\n<li><a href=\"evaluation/half_precision.html\">\u5728\u5355\u4e2a GPU \u4e0a\u8bc4\u4f30\u534a\u7cbe\u5ea6\u6a21\u578b</a></li> <ul>\n<li><a href=\"evaluation/llm_int8.html\">\u6b63\u5728\u8bc4\u4f30 llm.int8 () \u6a21\u578b</a></li></ul>\n<p><strong>\u5b98\u65b9\u7684 <a href=\"https://www.eleuther.ai\">Eleuther</a> GPT-NOEX \u662f\u6e90\u4ee3\u7801\u53ef\u5728 <a href=\"https://github.com/eleutherai/gpt-neox\">eleutherai/gpt-neox</a> \u83b7\u5f97\u3002</strong></p>\n",
 "GPT-NeoX": "GPT-neox",
 "Simple GPT-NeoX implementation": "\u7b80\u5355\u7684 GPT-NEOX \u5b9e\u73b0"
}