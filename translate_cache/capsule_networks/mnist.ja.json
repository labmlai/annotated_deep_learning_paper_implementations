{
 "<h1>Classify MNIST digits with Capsule Networks</h1>\n<p>This is an annotated PyTorch code to classify MNIST digits with PyTorch.</p>\n<p>This paper implements the experiment described in paper <a href=\"https://arxiv.org/abs/1710.09829\">Dynamic Routing Between Capsules</a>.</p>\n": "<h1>\u30ab\u30d7\u30bb\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u3088\u308b MNIST \u30c7\u30a3\u30b8\u30c3\u30c8\u306e\u5206\u985e</h1>\n<p>\u3053\u308c\u306f\u3001MNIST\u306e\u6570\u5b57\u3092PyTorch\u3067\u5206\u985e\u3059\u308b\u305f\u3081\u306e\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u4ed8\u304d\u306ePyTorch\u30b3\u30fc\u30c9\u3067\u3059\u3002</p>\n<p>\u3053\u306e\u8ad6\u6587\u3067\u306f\u3001\u8ad6\u6587\u300c<a href=\"https://arxiv.org/abs/1710.09829\">\u30ab\u30d7\u30bb\u30eb\u9593\u306e\u52d5\u7684\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0</a>\u300d\u3067\u8aac\u660e\u3055\u308c\u3066\u3044\u308b\u5b9f\u9a13\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002</p>\n",
 "<h2>Model for classifying MNIST digits</h2>\n": "<h2>MNIST \u30c7\u30a3\u30b8\u30c3\u30c8\u3092\u5206\u985e\u3059\u308b\u305f\u3081\u306e\u30e2\u30c7\u30eb</h2>\n",
 "<p> <span translate=no>_^_0_^_</span> are the MNIST images, with shape <span translate=no>_^_1_^_</span></p>\n": "<p><span translate=no>_^_0_^_</span>MNIST \u306e\u753b\u50cf\u306f\u5f62\u72b6\u4ed8\u304d\u3067\u3059 <span translate=no>_^_1_^_</span></p>\n",
 "<p> Configurations with MNIST data and Train &amp; Validation setup</p>\n": "<p>MNIST\u30c7\u30fc\u30bf\u3068\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u691c\u8a3c\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3092\u542b\u3080\u69cb\u6210</p>\n",
 "<p> Run the experiment</p>\n": "<p>\u5b9f\u9a13\u3092\u5b9f\u884c\u3059\u308b</p>\n",
 "<p> This method gets called by the trainer</p>\n": "<p>\u3053\u306e\u30e1\u30bd\u30c3\u30c9\u306f\u30c8\u30ec\u30fc\u30ca\u30fc\u306b\u3088\u3063\u3066\u547c\u3073\u51fa\u3055\u308c\u307e\u3059</p>\n",
 "<p>Calculate the total loss </p>\n": "<p>\u7dcf\u640d\u5931\u306e\u8a08\u7b97</p>\n",
 "<p>Call accuracy metric </p>\n": "<p>\u901a\u8a71\u7cbe\u5ea6\u6307\u6a19</p>\n",
 "<p>Create a mask to maskout all the other capsules </p>\n": "<p>\u30de\u30b9\u30af\u3092\u4f5c\u6210\u3057\u3066\u3001\u4ed6\u306e\u3059\u3079\u3066\u306e\u30ab\u30d7\u30bb\u30eb\u3092\u8986\u3044\u96a0\u3057\u3066\u304f\u3060\u3055\u3044</p>\n",
 "<p>First convolution layer has <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span> convolution kernels </p>\n": "<p>\u6700\u521d\u306e\u7573\u307f\u8fbc\u307f\u5c64\u306b\u306f<span translate=no>_^_0_^_</span>\u3001<span translate=no>_^_1_^_</span>\u7573\u307f\u8fbc\u307f\u30ab\u30fc\u30cd\u30eb\u304c\u3042\u308a\u307e\u3059</p>\n",
 "<p>Get masks for reconstructioon </p>\n": "<p>\u5fa9\u8208\u7528\u30de\u30b9\u30af\u3092\u5165\u624b</p>\n",
 "<p>Get the images and labels and move them to the model&#x27;s device </p>\n": "<p>\u753b\u50cf\u3068\u30e9\u30d9\u30eb\u3092\u53d6\u5f97\u3057\u3066\u30e2\u30c7\u30eb\u306e\u30c7\u30d0\u30a4\u30b9\u306b\u79fb\u52d5\u3057\u307e\u3059</p>\n",
 "<p>Increment step in training mode </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30e2\u30fc\u30c9\u3067\u306e\u30a4\u30f3\u30af\u30ea\u30e1\u30f3\u30c8\u30b9\u30c6\u30c3\u30d7</p>\n",
 "<p>Log parameters and gradients </p>\n": "<p>\u30ed\u30b0\u30d1\u30e9\u30e1\u30fc\u30bf\u3068\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3</p>\n",
 "<p>Mask the digit capsules to get only the capsule that made the prediction and take it through decoder to get reconstruction </p>\n": "<p>\u6570\u5b57\u306e\u30ab\u30d7\u30bb\u30eb\u3092\u30de\u30b9\u30af\u3057\u3066\u4e88\u6e2c\u3092\u884c\u3063\u305f\u30ab\u30d7\u30bb\u30eb\u306e\u307f\u3092\u53d6\u5f97\u3057\u3001\u305d\u308c\u3092\u30c7\u30b3\u30fc\u30c0\u30fc\u306b\u901a\u3057\u3066\u518d\u69cb\u6210\u3057\u307e\u3059</p>\n",
 "<p>Pass through the first convolution layer. Output of this layer has shape <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6700\u521d\u306e\u7573\u307f\u8fbc\u307f\u5c64\u3092\u901a\u904e\u3057\u307e\u3059\u3002\u3053\u306e\u30ec\u30a4\u30e4\u30fc\u306e\u51fa\u529b\u306b\u306f\u5f62\u72b6\u304c\u3042\u308a\u307e\u3059 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Pass through the second convolution layer. Output of this has shape <span translate=no>_^_0_^_</span>. <em>Note that this layer has a stride length of <span translate=no>_^_1_^_</span></em>. </p>\n": "<p>2 \u756a\u76ee\u306e\u7573\u307f\u8fbc\u307f\u5c64\u3092\u901a\u904e\u3057\u307e\u3059\u3002\u3053\u308c\u306e\u51fa\u529b\u306b\u306f\u5f62\u72b6\u304c\u3042\u308a\u307e\u3059<span translate=no>_^_0_^_</span>\u3002<em><span translate=no>_^_1_^_</span>\u3053\u306e\u30ec\u30a4\u30e4\u30fc\u306e\u30b9\u30c8\u30e9\u30a4\u30c9\u306e\u9577\u3055\u306f\u3067\u3042\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044</em></p>\u3002\n",
 "<p>Print losses and accuracy to screen </p>\n": "<p>\u5370\u5237\u30ed\u30b9\u3068\u753b\u9762\u306e\u7cbe\u5ea6</p>\n",
 "<p>Reshape the reconstruction to match the image dimensions </p>\n": "<p>\u753b\u50cf\u306e\u30b5\u30a4\u30ba\u306b\u5408\u308f\u305b\u3066\u518d\u69cb\u6210\u306e\u5f62\u72b6\u3092\u5909\u66f4</p>\n",
 "<p>Resize and permutate to get the capsules </p>\n": "<p>\u30b5\u30a4\u30ba\u3092\u5909\u66f4\u3057\u3066\u4e26\u3079\u66ff\u3048\u3066\u30ab\u30d7\u30bb\u30eb\u306b\u3059\u308b</p>\n",
 "<p>Routing layer gets the <span translate=no>_^_0_^_</span> primary capsules and produces <span translate=no>_^_1_^_</span> capsules. Each of the primary capsules have <span translate=no>_^_2_^_</span> features, while output capsules (Digit Capsules) have <span translate=no>_^_3_^_</span> features. The routing algorithm iterates <span translate=no>_^_4_^_</span> times. </p>\n": "<p><span translate=no>_^_0_^_</span>\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u5c64\u306f\u4e00\u6b21\u30ab\u30d7\u30bb\u30eb\u3092\u53d6\u5f97\u3057\u3001<span translate=no>_^_1_^_</span>\u30ab\u30d7\u30bb\u30eb\u3092\u751f\u6210\u3057\u307e\u3059\u3002<span translate=no>_^_2_^_</span>\u5404\u30d7\u30e9\u30a4\u30de\u30ea\u30fc\u30ab\u30d7\u30bb\u30eb\u306b\u306f\u7279\u5fb4\u304c\u3042\u308a\u3001\u51fa\u529b\u30ab\u30d7\u30bb\u30eb\uff08\u30c7\u30a3\u30b8\u30c3\u30c8\u30ab\u30d7\u30bb\u30eb\uff09\u306b\u306f\u7279\u5fb4\u304c\u3042\u308a\u307e\u3059\u3002<span translate=no>_^_3_^_</span><span translate=no>_^_4_^_</span>\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u4f55\u56de\u3082\u7e70\u308a\u8fd4\u3057\u307e\u3059\u3002</p>\n",
 "<p>Run the model </p>\n": "<p>\u30e2\u30c7\u30eb\u3092\u5b9f\u884c</p>\n",
 "<p>Set the model </p>\n": "<p>\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\u3059\u308b</p>\n",
 "<p>Set the model mode </p>\n": "<p>\u30e2\u30c7\u30eb\u30e2\u30fc\u30c9\u3092\u8a2d\u5b9a</p>\n",
 "<p>Squash the capsules </p>\n": "<p>\u30ab\u30d7\u30bb\u30eb\u3092\u62bc\u3057\u3064\u3076\u3059</p>\n",
 "<p>Take them through the router to get digit capsules. This has shape <span translate=no>_^_0_^_</span>. </p>\n": "<p>\u305d\u308c\u3089\u3092\u30eb\u30fc\u30bf\u30fc\u306b\u901a\u3057\u3066\u3001\u6570\u5b57\u306e\u30ab\u30d7\u30bb\u30eb\u3092\u5165\u624b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u3053\u308c\u306f\u5f62\u304c\u3042\u308a\u307e\u3059<span translate=no>_^_0_^_</span>\u3002</p>\n",
 "<p>The prediction by the capsule network is the capsule with longest length </p>\n": "<p>\u30ab\u30d7\u30bb\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u3088\u308b\u4e88\u6e2c\u3067\u306f\u3001\u9577\u3055\u304c\u6700\u3082\u9577\u3044\u30ab\u30d7\u30bb\u30eb\u3067\u3059</p>\n",
 "<p>The second layer (Primary Capsules) s a convolutional capsule layer with <span translate=no>_^_0_^_</span> channels of convolutional <span translate=no>_^_1_^_</span> capsules (<span translate=no>_^_2_^_</span> features per capsule). That is, each primary capsule contains 8 convolutional units with a 9 \u00d7 9 kernel and a stride of 2. In order to implement this we create a convolutional layer with <span translate=no>_^_3_^_</span> channels and reshape and permutate its output to get the capsules of <span translate=no>_^_4_^_</span> features each. </p>\n": "<p>2 \u756a\u76ee\u306e\u5c64 (\u30d7\u30e9\u30a4\u30de\u30ea\u30fc\u30ab\u30d7\u30bb\u30eb) \u306f\u3001\u7573\u307f\u8fbc\u307f\u30ab\u30d7\u30bb\u30eb (\u30ab\u30d7\u30bb\u30eb\u3054\u3068\u306e\u30d5\u30a3\u30fc\u30c1\u30e3) <span translate=no>_^_0_^_</span> <span translate=no>_^_1_^_</span> \u306e\u30c1\u30e3\u30cd\u30eb\u304c\u3042\u308b\u7573\u307f\u8fbc\u307f\u30ab\u30d7\u30bb\u30eb\u5c64\u3067\u3059\u3002<span translate=no>_^_2_^_</span>\u3064\u307e\u308a\u3001\u5404\u30d7\u30e9\u30a4\u30de\u30ea\u30ab\u30d7\u30bb\u30eb\u306b\u306f\u30019 \u00d7 9 \u306e\u30ab\u30fc\u30cd\u30eb\u3068\u30b9\u30c8\u30e9\u30a4\u30c9\u304c 2 \u306e 8 \u3064\u306e\u7573\u307f\u8fbc\u307f\u30e6\u30cb\u30c3\u30c8\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3092\u5b9f\u88c5\u3059\u308b\u305f\u3081\u306b\u3001<span translate=no>_^_3_^_</span>\u30c1\u30e3\u30cd\u30eb\u3092\u542b\u3080\u7573\u307f\u8fbc\u307f\u5c64\u3092\u4f5c\u6210\u3057\u3001\u305d\u306e\u51fa\u529b\u3092\u5f62\u72b6\u5909\u66f4\u304a\u3088\u3073\u7f6e\u63db\u3057\u3066\u3001\u305d\u308c\u305e\u308c\u306e\u7279\u5fb4\u306e\u30ab\u30d7\u30bb\u30eb\u3092\u53d6\u5f97\u3057\u307e\u3059</p>\u3002<span translate=no>_^_4_^_</span>\n",
 "<p>This is the decoder mentioned in the paper. It takes the outputs of the <span translate=no>_^_0_^_</span> digit capsules, each with <span translate=no>_^_1_^_</span> features to reproduce the image. It goes through linear layers of sizes <span translate=no>_^_2_^_</span> and <span translate=no>_^_3_^_</span> with <span translate=no>_^_4_^_</span> activations. </p>\n": "<p>\u3053\u308c\u306f\u8ad6\u6587\u3067\u8a00\u53ca\u3055\u308c\u3066\u3044\u308b\u30c7\u30b3\u30fc\u30c0\u30fc\u3067\u3059\u3002<span translate=no>_^_0_^_</span>\u6570\u5b57\u30ab\u30d7\u30bb\u30eb\u306e\u51fa\u529b\u3092\u53d7\u3051\u53d6\u308a\u3001<span translate=no>_^_1_^_</span>\u305d\u308c\u305e\u308c\u306b\u753b\u50cf\u3092\u518d\u73fe\u3059\u308b\u6a5f\u80fd\u304c\u3042\u308a\u307e\u3059\u3002<span translate=no>_^_2_^_</span><span translate=no>_^_3_^_</span><span translate=no>_^_4_^_</span>\u30b5\u30a4\u30ba\u3084\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30b7\u30e7\u30f3\u304c\u76f4\u7dda\u7684\u306b\u7e70\u308a\u8fd4\u3055\u308c\u307e\u3059</p>\u3002\n",
 "<p>We need to set the metrics to calculate them for the epoch for training and validation </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u691c\u8a3c\u306e\u305f\u3081\u306b\u3001\u30a8\u30dd\u30c3\u30af\u306b\u5408\u308f\u305b\u3066\u305d\u308c\u3089\u3092\u8a08\u7b97\u3059\u308b\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u8a2d\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059</p>\n",
 "<p>Whether to log activations </p>\n": "<p>\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30b7\u30e7\u30f3\u3092\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b\u304b\u3069\u3046\u304b</p>\n",
 "Classify MNIST digits with Capsule Networks": "\u30ab\u30d7\u30bb\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u3088\u308b MNIST \u30c7\u30a3\u30b8\u30c3\u30c8\u306e\u5206\u985e",
 "Code for training Capsule Networks on MNIST dataset": "MNIST \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067 Capsule \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u305f\u3081\u306e\u30b3\u30fc\u30c9"
}