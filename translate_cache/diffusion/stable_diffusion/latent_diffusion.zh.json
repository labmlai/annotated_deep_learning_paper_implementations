{
 "<h1>Latent Diffusion Models</h1>\n<p>Latent diffusion models use an auto-encoder to map between image space and latent space. The diffusion model works on the latent space, which makes it a lot easier to train. It is based on paper <a href=\"https://arxiv.org/abs/2112.10752\">High-Resolution Image Synthesis with Latent Diffusion Models</a>.</p>\n<p>They use a pre-trained auto-encoder and train the diffusion U-Net on the latent space of the pre-trained auto-encoder.</p>\n<p>For a simpler diffusion implementation refer to our <a href=\"../ddpm/index.html\">DDPM implementation</a>. We use same notations for <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span> schedules, etc.</p>\n": "<h1>\u6f5c\u5728\u6269\u6563\u6a21\u578b</h1>\n<p>\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u5728\u56fe\u50cf\u7a7a\u95f4\u548c\u6f5c\u5728\u7a7a\u95f4\u4e4b\u95f4\u8fdb\u884c\u6620\u5c04\u3002\u6269\u6563\u6a21\u578b\u9002\u7528\u4e8e\u6f5c\u5728\u7a7a\u95f4\uff0c\u8fd9\u4f7f\u5f97\u8bad\u7ec3\u53d8\u5f97\u5bb9\u6613\u5f97\u591a\u3002\u5b83\u57fa\u4e8e<a href=\"https://arxiv.org/abs/2112.10752\">\u5e26\u6709\u6f5c\u5728\u6269\u6563\u6a21\u578b\u7684\u7eb8\u8d28\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210</a>\u3002</p>\n<p>\u5b83\u4eec\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5728\u9884\u8bad\u7ec3\u7684\u81ea\u52a8\u7f16\u7801\u5668\u7684\u6f5c\u5728\u7a7a\u95f4\u4e0a\u8bad\u7ec3\u6269\u6563 U-Net\u3002</p>\n<p>\u6709\u5173\u66f4\u7b80\u5355\u7684\u6269\u6563\u5b9e\u73b0\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 <a href=\"../ddpm/index.html\">DDPM \u5b9e\u73b0</a>\u3002\u6211\u4eec\u5bf9<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u65f6\u95f4\u8868\u7b49\u4f7f\u7528\u76f8\u540c\u7684\u7b26\u53f7\u3002</p>\n",
 "<h2>Latent diffusion model</h2>\n<p>This contains following components:</p>\n<ul><li><a href=\"model/autoencoder.html\">AutoEncoder</a> </li>\n<li><a href=\"model/unet.html\">U-Net</a> with <a href=\"model/unet_attention.html\">attention</a> </li>\n<li><a href=\"model/clip_embedder.html\">CLIP embeddings generator</a></li></ul>\n": "<h2>\u6f5c\u5728\u6269\u6563\u6a21\u578b</h2>\n<p>\u5b83\u5305\u542b\u4ee5\u4e0b\u7ec4\u4ef6\uff1a</p>\n<ul><li><a href=\"model/autoencoder.html\">\u81ea\u52a8\u7f16\u7801\u5668</a></li>\n<li><a href=\"model/unet_attention.html\">\u5907\u53d7\u5173\u6ce8</a>\u7684 <a href=\"model/unet.html\">U-Net</a></li>\n<li><a href=\"model/clip_embedder.html\">CLIP \u5d4c\u5165\u5f0f\u751f\u6210\u5668</a></li></ul>\n",
 "<h3>Get <a href=\"model/clip_embedder.html\">CLIP embeddings</a> for a list of text prompts</h3>\n": "<h3>\u83b7\u53d6 <a href=\"model/clip_embedder.html\">CLIP \u5d4c\u5165</a>\u4ee5\u83b7\u53d6\u6587\u672c\u63d0\u793a\u5217\u8868</h3>\n",
 "<h3>Get image from the latent representation</h3>\n<p>We scale down by the scaling factor and then decode.</p>\n": "<h3>\u4ece\u6f5c\u5728\u8868\u793a\u4e2d\u83b7\u53d6\u56fe\u50cf</h3>\n<p>\u6211\u4eec\u6309\u7f29\u653e\u7cfb\u6570\u5411\u4e0b\u7f29\u653e\uff0c\u7136\u540e\u89e3\u7801\u3002</p>\n",
 "<h3>Get model device</h3>\n": "<h3>\u83b7\u53d6\u8bbe\u5907\u6a21\u578b</h3>\n",
 "<h3>Get scaled latent space representation of the image</h3>\n<p>The encoder output is a distribution. We sample from that and multiply by the scaling factor.</p>\n": "<h3>\u83b7\u53d6\u56fe\u50cf\u7684\u7f29\u653e\u6f5c\u5728\u7a7a\u95f4\u8868\u793a</h3>\n<p>\u7f16\u7801\u5668\u8f93\u51fa\u662f\u5206\u5e03\u5f0f\u3002\u6211\u4eec\u4ece\u4e2d\u53d6\u6837\u5e76\u4e58\u4ee5\u7f29\u653e\u7cfb\u6570\u3002</p>\n",
 "<h3>Predict noise</h3>\n<p>Predict noise given the latent representation <span translate=no>_^_0_^_</span>, time step <span translate=no>_^_1_^_</span>, and the conditioning context <span translate=no>_^_2_^_</span>.</p>\n<p><span translate=no>_^_3_^_</span></p>\n": "<h3>\u9884\u6d4b\u566a\u97f3</h3>\n<p>\u6839\u636e\u6f5c\u5728\u8868\u793a<span translate=no>_^_0_^_</span>\u3001\u65f6\u95f4\u6b65<span translate=no>_^_1_^_</span>\u957f\u548c\u6761\u4ef6\u73af\u5883\u9884\u6d4b\u566a\u58f0<span translate=no>_^_2_^_</span>\u3002</p>\n<p><span translate=no>_^_3_^_</span></p>\n",
 "<p> <em>This is an empty wrapper class around the <a href=\"model/unet.html\">U-Net</a>. We keep this to have the same model structure as <a href=\"https://github.com/CompVis/stable-diffusion\">CompVis/stable-diffusion</a> so that we do not have to map the checkpoint weights explicitly</em>.</p>\n": "<p><em>\u8fd9\u662f\u56f4\u7ed5 <a href=\"model/unet.html\">U-Net</a> \u7684\u7a7a\u5305\u88c5\u7c7b\u3002\u6211\u4eec\u4fdd\u6301\u5b83\u4e0e <a href=\"https://github.com/CompVis/stable-diffusion\">compVIS/Stable-</a> Difusion \u76f8\u540c\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u8fd9\u6837\u6211\u4eec\u5c31\u4e0d\u5fc5\u660e\u786e\u5730\u6620\u5c04\u68c0\u67e5\u70b9\u6743\u91cd</em>\u3002</p>\n",
 "<p><a href=\"model/clip_embedder.html\">CLIP embeddings generator</a> </p>\n": "<p><a href=\"model/clip_embedder.html\">CLIP \u5d4c\u5165\u5f0f\u751f\u6210\u5668</a></p>\n",
 "<p><span translate=no>_^_0_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> schedule </p>\n": "<p><span translate=no>_^_0_^_</span>\u65f6\u95f4\u8868</p>\n",
 "<p>Auto-encoder and scaling factor </p>\n": "<p>\u81ea\u52a8\u7f16\u7801\u5668\u548c\u7f29\u653e\u7cfb\u6570</p>\n",
 "<p>Number of steps <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6b65\u6570<span translate=no>_^_0_^_</span></p>\n",
 "<p>Wrap the <a href=\"model/unet.html\">U-Net</a> to keep the same model structure as <a href=\"https://github.com/CompVis/stable-diffusion\">CompVis/stable-diffusion</a>. </p>\n": "<p>\u5c01\u88c5 <a href=\"model/unet.html\">U-Net</a> \u4ee5\u4fdd\u6301\u4e0e <a href=\"https://github.com/CompVis/stable-diffusion\">compVIS/Stable-</a> Difusion \u76f8\u540c\u7684\u6a21\u578b\u7ed3\u6784\u3002</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  is the <a href=\"model/unet.html\">U-Net</a> that predicts noise  <span translate=no>_^_1_^_</span>, in latent space </li>\n<li><span translate=no>_^_2_^_</span>  is the <a href=\"model/autoencoder.html\">AutoEncoder</a> </li>\n<li><span translate=no>_^_3_^_</span>  is the <a href=\"model/clip_embedder.html\">CLIP embeddings generator</a> </li>\n<li><span translate=no>_^_4_^_</span>  is the scaling factor for the latent space. The encodings of  the autoencoder are scaled by this before feeding into the U-Net. </li>\n<li><span translate=no>_^_5_^_</span>  is the number of diffusion steps <span translate=no>_^_6_^_</span>. </li>\n<li><span translate=no>_^_7_^_</span>  is the start of the <span translate=no>_^_8_^_</span> schedule. </li>\n<li><span translate=no>_^_9_^_</span>  is the end of the <span translate=no>_^_10_^_</span> schedule.</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u9884\u6d4b\u6f5c\u5728\u7a7a\u95f4\u4e2d\u566a\u58f0<span translate=no>_^_1_^_</span>\u7684 <a href=\"model/unet.html\">U-Ne</a> t</li>\n<li><span translate=no>_^_2_^_</span>\u662f<a href=\"model/autoencoder.html\">\u81ea\u52a8\u7f16\u7801\u5668</a></li>\n<li><span translate=no>_^_3_^_</span>\u662f <a href=\"model/clip_embedder.html\">CLIP \u5d4c\u5165\u751f\u6210\u5668</a></li>\n<li><span translate=no>_^_4_^_</span>\u662f\u6f5c\u5728\u7a7a\u95f4\u7684\u7f29\u653e\u7cfb\u6570\u3002\u5728\u9988\u5165 U-Net \u4e4b\u524d\uff0c\u81ea\u52a8\u7f16\u7801\u5668\u7684\u7f16\u7801\u4f1a\u6309\u6b64\u8fdb\u884c\u7f29\u653e\u3002</li>\n<li><span translate=no>_^_5_^_</span>\u662f\u6269\u6563\u6b65\u9aa4\u7684\u6570\u91cf<span translate=no>_^_6_^_</span>\u3002</li>\n<li><span translate=no>_^_7_^_</span>\u662f<span translate=no>_^_8_^_</span>\u65f6\u95f4\u8868\u7684\u5f00\u59cb\u3002</li>\n<li><span translate=no>_^_9_^_</span>\u662f<span translate=no>_^_10_^_</span>\u65f6\u95f4\u8868\u7684\u7ed3\u675f\u3002</li></ul>\n",
 "Annotated PyTorch implementation/tutorial of latent diffusion models from paper High-Resolution Image Synthesis with Latent Diffusion Models": "\u5e26\u6ce8\u91ca\u7684 PyTorch \u5b9e\u73b0/\u6559\u7a0b\u6765\u81ea\u8bba\u6587\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4f7f\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\u8fdb\u884c\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210",
 "Latent Diffusion Models": "\u6f5c\u5728\u6269\u6563\u6a21\u578b"
}