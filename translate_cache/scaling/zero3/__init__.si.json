{
 "<h1>Zero-DP Memory Optimization</h1>\n<p>This is an implementation of Zero-DP introduced in the paper <a href=\"https://arxiv.org/abs/1910.02054\">ZeRO: Memory Optimization Towards Training A Trillion Parameter Models</a>,</p>\n<p>It keeps shards of the optimizer state, gradients and parameters into multiple devices/nodes. It reduces the memory consumption to <span translate=no>_^_0_^_</span> of the original model, where <span translate=no>_^_1_^_</span> is the number of parameters, <span translate=no>_^_2_^_</span> is the number of shards,  and <span translate=no>_^_3_^_</span> is number of optimizer bytes per parameter. <span translate=no>_^_4_^_</span> are the parameter and gradient memory assuming 16-bit precision; i.e. 2 bytes per parameter and gradient. <span translate=no>_^_5_^_</span> for Adam optimizer because it maintains a copy of parameters, and two moments per parameter in fp32.</p>\n<p>The communication volume of Zero-DP is <span translate=no>_^_6_^_</span>. For comparison data-parallel training has a communication volume of <span translate=no>_^_7_^_</span>.</p>\n<p>Although this is named <span translate=no>_^_8_^_</span>, we have only implemented the Zero-DP part of it and not the  Zero-R memory optimizations which target residual memory consumption. Out implementation supports training only a subset of parameters.</p>\n<p>This implementation is inspired by <a href=\"https://fairscale.readthedocs.io/en/stable/api/nn/fsdp.html\">Fairscale FSDP</a>.</p>\n<p><a href=\"finetune_neox.html\">Here&#x27;s a script to fine-tune</a> GPT NeoX using Zero-DP memory optimization.</p>\n": "<h1>\u0dc1\u0dd4\u0db1\u0dca\u0dba-\u0da9\u0dd3\u0db4\u0dd3\u0db8\u0dad\u0d9a \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab\u0dba</h1>\n<p>\u0db8\u0dd9\u0dba\u0d9a\u0da9\u0daf\u0dcf\u0dc3\u0dd2 \u0dc0\u0dbd \u0dc4\u0db3\u0dd4\u0db1\u0dca\u0dc0\u0dcf \u0daf\u0dd4\u0db1\u0dca \u0dc1\u0dd4\u0db1\u0dca\u0dba-\u0da9\u0dd3\u0db4\u0dd3 \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0d9a\u0dd2 <a href=\"https://arxiv.org/abs/1910.02054\">\u0dc1\u0dd4\u0db1\u0dca\u0dba: \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0dc0 \u0dc3\u0db3\u0dc4\u0dcf \u0db8\u0dad\u0d9a \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab\u0dba \u0da7\u0dca\u0dbb\u0dd2\u0dbd\u0dd2\u0dba\u0db1\u0dba\u0d9a\u0dca \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2 \u0d86\u0d9a\u0dd8\u0dad\u0dd2</a>,</p>\n<p>\u0d91\u0dba\u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab \u0dad\u0dad\u0dca\u0dc0\u0dba\u0dda, \u0dc1\u0dca\u0dbb\u0dda\u0dab\u0dd2\u0dba\u0dda \u0dc3\u0dc4 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db6\u0dc4\u0dd4 \u0d8b\u0db4\u0dcf\u0d82\u0d9c/\u0db1\u0ddd\u0da9\u0dca \u0dc0\u0dbd\u0da7 \u0dad\u0db6\u0dcf \u0d9c\u0db1\u0dd3. \u0d91\u0dba \u0db8\u0dd4\u0dbd\u0dca \u0d86\u0d9a\u0dd8\u0dad\u0dd2\u0dba\u0da7 \u0db8\u0dad\u0d9a \u0db4\u0dbb\u0dd2\u0db7\u0ddd\u0da2\u0db1\u0dba \u0d85\u0da9\u0dd4 \u0d9a\u0dbb\u0dba\u0dd2, \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2 \u0d9c\u0dab\u0db1 <span translate=no>_^_1_^_</span> \u0d9a\u0ddc\u0dad\u0dd0\u0db1\u0daf, \u0d9a\u0dd0\u0db6\u0dbd\u0dd2 \u0d9c\u0dab\u0db1 \u0daf <span translate=no>_^_3_^_</span> , <span translate=no>_^_0_^_</span> <span translate=no>_^_2_^_</span> \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0d9a\u0da7 \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab \u0db6\u0dba\u0dd2\u0da7\u0dca \u0d9c\u0dab\u0db1. <span translate=no>_^_4_^_</span> \u0db6\u0dd2\u0da7\u0dca 16-\u0db1\u0dd2\u0dbb\u0dc0\u0daf\u0dca\u0dba\u0dad\u0dcf\u0dc0 \u0d8b\u0db4\u0d9a\u0dbd\u0dca\u0db4\u0db1\u0dba \u0d9a\u0dbb\u0db1 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba \u0dc3\u0dc4 \u0dc1\u0dca\u0dbb\u0dda\u0dab\u0dd2\u0dba\u0dda \u0db8\u0dad\u0d9a\u0dba; \u0d91\u0db1\u0db8\u0dca \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0da7 \u0db6\u0dba\u0dd2\u0da7\u0dca 2 \u0d9a\u0dca \u0dc3\u0dc4 \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0dba. <span translate=no>_^_5_^_</span> \u0dc3\u0db3\u0dc4\u0dcf \u0d86\u0daf\u0db8\u0dca \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0d9a\u0dbb\u0dab\u0dba \u0d91\u0dba \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0d9c\u0dda \u0db4\u0dd2\u0da7\u0db4\u0dad\u0d9a\u0dca \u0dc3\u0dc4 fp32 \u0dc4\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0d9a\u0da7 \u0d85\u0dc0\u0dc3\u0dca\u0dae\u0dcf \u0daf\u0dd9\u0d9a\u0d9a\u0dca \u0db4\u0dc0\u0dad\u0dca\u0dc0\u0dcf \u0d9c\u0dd9\u0db1 \u0dba\u0db1 \u0db6\u0dd0\u0dc0\u0dd2\u0db1\u0dd2. </p>\n<p>\u0dc1\u0dd4\u0db1\u0dca\u0dba-\u0da9\u0dd3\u0db4\u0dd3\u0dc4\u0dd2 \u0dc3\u0db1\u0dca\u0db1\u0dd2\u0dc0\u0dda\u0daf\u0db1 \u0db4\u0dbb\u0dd2\u0db8\u0dcf\u0dc0 \u0dc0\u0dda <span translate=no>_^_6_^_</span>. \u0dc3\u0d82\u0dc3\u0db1\u0dca\u0daf\u0db1\u0dba \u0dc3\u0db3\u0dc4\u0dcf \u0daf\u0dad\u0dca\u0dad-\u0dc3\u0db8\u0dcf\u0db1\u0dca\u0dad\u0dbb \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0dc0 \u0dc3\u0db1\u0dca\u0db1\u0dd2\u0dc0\u0dda\u0daf\u0db1 \u0db4\u0dbb\u0dd2\u0db8\u0dcf\u0dc0\u0d9a\u0dca <span translate=no>_^_7_^_</span>\u0d87\u0dad. </p>\n<p>\u0db8\u0dd9\u0dba\u0db1\u0db8\u0dca \u0d9a\u0dbb \u0d87\u0dad\u0dad\u0dca <span translate=no>_^_8_^_</span>, \u0d85\u0db4 \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dbb \u0d87\u0dad\u0dca\u0dad\u0dda \u0d91\u0dc4\u0dd2 \u0dc1\u0dd4\u0db1\u0dca\u0dba-\u0da9\u0dd3\u0db4\u0dd3 \u0d9a\u0ddc\u0da7\u0dc3 \u0db4\u0db8\u0dab\u0d9a\u0dca \u0db8\u0dd2\u0dc3 \u0d85\u0dc0\u0dc1\u0dda\u0dc2 \u0db8\u0dad\u0d9a \u0db4\u0dbb\u0dd2\u0db7\u0ddd\u0da2\u0db1\u0dba \u0d89\u0dbd\u0d9a\u0dca\u0d9a \u0d9a\u0dbb\u0db1 Zero-R \u0db8\u0dad\u0d9a \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab\u0dba\u0db1\u0dca \u0db1\u0ddc\u0dc0\u0dda. \u0db4\u0dd2\u0da7\u0dad \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0dc0 \u0dc3\u0db3\u0dc4\u0dcf \u0dc3\u0dc4\u0dcf\u0dba \u0dc0\u0db1\u0dca\u0db1\u0dda \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0d9c\u0dda \u0d8b\u0db4 \u0d9a\u0dd4\u0dbd\u0d9a\u0dba\u0d9a\u0dca \u0db4\u0db8\u0dab\u0dd2. </p>\n<p>\u0db8\u0dd9\u0db8\u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 <a href=\"https://fairscale.readthedocs.io/en/stable/api/nn/fsdp.html\">Fairscale FSDP</a>\u0dc0\u0dd2\u0dc3\u0dd2\u0db1\u0dca \u0daf\u0dda\u0dc0\u0dcf\u0db1\u0dd4\u0db7\u0dcf\u0dc0\u0dba\u0dd9\u0db1\u0dca. </p>\n<p><a href=\"finetune_neox.html\">ZERO-DP \u0db8\u0dad\u0d9a \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab\u0dba \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db8\u0dd2\u0db1\u0dca GPT Neox \u0db8\u0db1\u0dcf\u0dc0 \u0dc3\u0d9a\u0dc3\u0dca \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0dc3\u0dca\u0d9a\u0dca\u0dbb\u0dd2\u0db4\u0dca\u0da7\u0dca \u0d91\u0d9a\u0d9a\u0dca \u0db8\u0dd9\u0db1\u0dca\u0db1</a> . </p>\n",
 "<h2>Sequential module for <span translate=no>_^_0_^_</span> layers</h2>\n": "<h2><span translate=no>_^_0_^_</span> \u0dc3\u0dca\u0dae\u0dbb \u0dc3\u0db3\u0dc4\u0dcf \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba</h2>\n",
 "<h2>Zero3 Layer</h2>\n<p>Each layer of the model (or a combination of a few consecutive layers) should be wrapped in this module.</p>\n": "<h2>Zero3\u0dc3\u0dca\u0dae\u0dbb\u0dba</h2>\n<p>\u0d86\u0d9a\u0dd8\u0dad\u0dd2\u0dba\u0dda\u0dc3\u0dd1\u0db8 \u0dc3\u0dca\u0dae\u0dbb\u0dba\u0d9a\u0dca\u0db8 (\u0dc4\u0ddd \u0d85\u0db1\u0dd4\u0dba\u0dcf\u0dad \u0dc3\u0dca\u0dae\u0dbb \u0d9a\u0dd2\u0dc4\u0dd2\u0db4\u0dba\u0d9a \u0d91\u0d9a\u0dad\u0dd4\u0dc0\u0d9a\u0dca) \u0db8\u0dd9\u0db8 \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba \u0dad\u0dd4\u0dc5 \u0d94\u0dad\u0dcf \u0dad\u0dd2\u0db6\u0dd2\u0dba \u0dba\u0dd4\u0dad\u0dd4\u0dba. </p>\n",
 "<h3>Backup the gradients of the current layer</h3>\n": "<h3>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0d8b\u0db4\u0dc3\u0dca\u0dae \u0d9a\u0dbb\u0db1\u0dca\u0db1</h3>\n",
 "<h3>Fetch the parameters from all shards</h3>\n<p>This will fetch all the parameter data from all the nodes and rebuild the parameters on each node.</p>\n": "<h3>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0d9a\u0dd0\u0db6\u0dbd\u0dd2 \u0dc0\u0dbd\u0dd2\u0db1\u0dca \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1</h3>\n<p>\u0db8\u0dd9\u0dba\u0dc3\u0dd2\u0dba\u0dbd\u0dd4 \u0db1\u0ddd\u0da9\u0dca \u0dc0\u0dbd\u0dd2\u0db1\u0dca \u0dc3\u0dd2\u0dba\u0dbd\u0dd4 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2 \u0daf\u0dad\u0dca\u0dad \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1\u0dcf \u0d85\u0dad\u0dbb \u0d91\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0db1\u0ddd\u0da9\u0dba\u0dda \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db1\u0dd0\u0dc0\u0dad \u0d9c\u0ddc\u0da9\u0db1\u0d9f\u0db1\u0dd4 \u0d87\u0dad. </p>\n",
 "<h3>Forward pass</h3>\n": "<h3>\u0d89\u0daf\u0dd2\u0dbb\u0dd2\u0dc3\u0dcf\u0db8\u0dcf\u0dbb\u0dca\u0dae\u0dba</h3>\n",
 "<h3>Get trainable chunk/shard of the parameters.</h3>\n<p>This is what we pass on to the optimizer on the current node.</p>\n": "<h3>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0d9c\u0dda\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0d9a\u0dd6\u0da9\u0dd4/\u0db8\u0da9\u0dd4 \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1. </h3>\n<p>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0db1\u0ddd\u0da9\u0dba\u0dda \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0d9a\u0dbb\u0dab\u0dba \u0dc0\u0dd9\u0dad \u0d85\u0db4 \u0dba\u0db1\u0dca\u0db1\u0dda \u0db8\u0dd9\u0dba\u0dba\u0dd2. </p>\n",
 "<h4>Add backward hooks to the parameters of the current layer.</h4>\n": "<h4>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0db3\u0dc4\u0dcf \u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3 \u0d9a\u0ddc\u0d9a\u0dd4 \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1. </h4>\n",
 "<h4>Cleanup the parameter data</h4>\n<p>This will release all the memory used by the layer parameters.</p>\n": "<h4>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0daf\u0dad\u0dca\u0dad \u0db4\u0dd2\u0dbb\u0dd2\u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1</h4>\n<p>\u0db8\u0dd9\u0dba\u0dc3\u0dca\u0dae\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc0\u0dd2\u0dc3\u0dd2\u0db1\u0dca \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db1 \u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db8 \u0db8\u0dad\u0d9a\u0dba \u0db8\u0dd4\u0daf\u0dcf \u0dc4\u0dbb\u0dd2\u0db1\u0dd4 \u0d87\u0dad. </p>\n",
 "<h4>Create an empty tensor of the given shape.</h4>\n": "<h4>\u0daf\u0dd3\u0d87\u0dad\u0dd2 \u0dc4\u0dd0\u0da9\u0dba\u0dda \u0dc4\u0dd2\u0dc3\u0dca \u0da7\u0dd9\u0db1\u0dca\u0dc3\u0dbb\u0dba\u0d9a\u0dca \u0dc3\u0dcf\u0daf\u0db1\u0dca\u0db1. </h4>\n",
 "<h4>Handle a backward event</h4>\n<p>This gets called by parameter backward hooks and the module backward hook.</p>\n": "<h4>\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3\u0dc3\u0dd2\u0daf\u0dd4\u0dc0\u0dd3\u0db8\u0d9a\u0dca \u0dc4\u0dc3\u0dd4\u0dbb\u0dd4\u0dc0\u0db1\u0dca\u0db1</h4>\n<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3 \u0d9a\u0ddc\u0d9a\u0dd4 \u0dc3\u0dc4 \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba\u0dda \u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3 \u0d9a\u0ddc\u0d9a\u0dca\u0d9a \u0db8\u0d9c\u0dd2\u0db1\u0dca \u0db8\u0dd9\u0dba \u0d9a\u0dd0\u0db3\u0dc0\u0db1\u0dd4 \u0dbd\u0dd0\u0db6\u0dda. </p>\n",
 "<h4>Merge all the parameters and pad it so that it&#x27;s divisible by <span translate=no>_^_0_^_</span>.</h4>\n": "<h4>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0d92\u0d9a\u0dcf\u0db6\u0daf\u0dca\u0db0 \u0d9a\u0dbb \u0d91\u0dba \u0db6\u0dd9\u0daf\u0dd2\u0dba \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc0\u0db1 \u0db4\u0dbb\u0dd2\u0daf\u0dd2 \u0db4\u0dd1\u0da9\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 <span translate=no>_^_0_^_</span>. </h4>\n",
 "<h4>Module backward hook</h4>\n": "<h4>\u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3 \u0d9a\u0ddc\u0d9a\u0dca\u0d9a</h4>\n",
 "<h4>Parameter backward hook</h4>\n": "<h4>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3 \u0d9a\u0ddc\u0d9a\u0dca\u0d9a</h4>\n",
 "<p> </p>\n": "<p> </p>\n",
 "<p>Accumulate the gradients of each shard. It scatters the buffers across the nodes, and each node accumulates (reduces) the tensors it receives. </p>\n": "<p>\u0d91\u0d9a\u0dca\u0d91\u0d9a\u0dca \u0dc1\u0dcf\u0d9a\u0dba\u0dda \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0dc3\u0db8\u0dd4\u0da0\u0dca\u0da0\u0dba \u0d9a\u0dbb\u0db1\u0dca\u0db1. \u0d91\u0dba \u0db1\u0ddd\u0da9\u0dca \u0dc4\u0dbb\u0dc4\u0dcf \u0db6\u0dc6\u0dbb \u0dc0\u0dd2\u0dc3\u0dd2\u0dbb\u0dd3 \u0dba\u0db1 \u0d85\u0dad\u0dbb \u0dc3\u0dd1\u0db8 \u0db1\u0ddd\u0da9\u0dba\u0d9a\u0dca\u0db8 \u0d91\u0dba\u0da7 \u0dbd\u0dd0\u0db6\u0dd9\u0db1 \u0d86\u0dad\u0dad\u0dd3\u0db1\u0dca \u0d91\u0d9a\u0dad\u0dd4 \u0dc0\u0dda (\u0d85\u0da9\u0dd4 \u0d9a\u0dbb\u0dba\u0dd2). </p>\n",
 "<p>Add a backward hook. This gets called when the gradients relative to the module are computed. </p>\n": "<p>\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3\u0d9a\u0ddc\u0d9a\u0dca\u0d9a\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1. \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba\u0da7 \u0dc3\u0dcf\u0db4\u0dda\u0d9a\u0dca\u0dc2\u0dc0 \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0d9c\u0dab\u0db1\u0dba \u0d9a\u0dc5 \u0dc0\u0dd2\u0da7 \u0db8\u0dd9\u0dba \u0d9a\u0dd0\u0db3\u0dc0\u0db1\u0dd4 \u0dbd\u0dd0\u0db6\u0dda. </p>\n",
 "<p>Add backward hooks to the parameters of the current layer if autograd is enabled. </p>\n": "<p>\u0d94\u0da7\u0ddd\u0d9c\u0dca\u0dbb\u0dcf\u0da9\u0dca\u0dc3\u0d9a\u0dca\u0dbb\u0dd3\u0dba \u0d9a\u0dbb \u0d87\u0dad\u0dca\u0db1\u0db8\u0dca \u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca \u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0db3\u0dc4\u0dcf \u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3 \u0d9a\u0ddc\u0d9a\u0dd4 \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1. </p>\n",
 "<p>Add the backward hook </p>\n": "<p>\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3\u0d9a\u0ddc\u0d9a\u0dca\u0d9a \u0d91\u0d9a\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>All parameters should have the same type </p>\n": "<p>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db8\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0d91\u0d9a\u0db8 \u0dc0\u0dbb\u0dca\u0d9c\u0dba\u0dda \u0dad\u0dd2\u0db6\u0dd2\u0dba \u0dba\u0dd4\u0dad\u0dd4\u0dba </p>\n",
 "<p>An empty tensor to receive the trainable and fixed parameters combined </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0d92\u0d9a\u0dcf\u0db6\u0daf\u0dca\u0db0 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0dc4\u0dd2\u0dc3\u0dca \u0da7\u0dd9\u0db1\u0dca\u0dc3\u0dbb\u0dba\u0d9a\u0dca </p>\n",
 "<p>Assign the values from the continuous tensor </p>\n": "<p>\u0d85\u0d9b\u0dab\u0dca\u0da9\u0d86\u0dad\u0dad\u0dd2\u0dba\u0dd9\u0db1\u0dca \u0d85\u0d9c\u0dba\u0db1\u0dca \u0db4\u0dd0\u0dc0\u0dbb\u0dd3\u0db8 </p>\n",
 "<p>Broadcast the sizes </p>\n": "<p>\u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0dc0\u0dd2\u0d9a\u0dcf\u0dc1\u0db1\u0dba \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Buffer to store the gradients </p>\n": "<p>\u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a\u0d9c\u0db6\u0da9\u0dcf \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0db6\u0dc6\u0dbb\u0dba </p>\n",
 "<p>CUDA stream to back up (accumulate) gradients </p>\n": "<p>\u0d8b\u0db4\u0dc3\u0dca\u0dae\u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 CUDA \u0db0\u0dcf\u0dbb\u0dcf\u0dc0 (\u0dc3\u0db8\u0dd4\u0da0\u0dca\u0da0\u0dba) \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a </p>\n",
 "<p>CUDA stream to backup/accumulate gradients </p>\n": "<p>\u0d8b\u0db4\u0dc3\u0dca\u0dae/\u0dc3\u0db8\u0dd4\u0da0\u0dca\u0da0\u0dba\u0db5\u0dbd\u0dba \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 CDA \u0d87\u0dc5 </p>\n",
 "<p>CUDA stream to featch parameters </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0db4\u0dd2\u0dc4\u0dcf\u0da7\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 CUDA \u0db0\u0dcf\u0dbb\u0dcf\u0dc0 </p>\n",
 "<p>CUDA stream to fetch parameters </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0dbd\u0db6\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8\u0da7 CUDA \u0db0\u0dcf\u0dbb\u0dcf\u0dc0 </p>\n",
 "<p>Calculate the chunk sizes of trainable and fixed params </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dca \u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab \u0d9c\u0dab\u0db1\u0dba \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Change the storage size of the parameter. This was set to <span translate=no>_^_0_^_</span> when we cleaned up the parameters. </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0dda\u0d9c\u0db6\u0da9\u0dcf \u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0dba \u0dc0\u0dd9\u0db1\u0dc3\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1. \u0d85\u0db4\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db4\u0dd2\u0dbb\u0dd2\u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dc5 <span translate=no>_^_0_^_</span> \u0dc0\u0dd2\u0da7 \u0db8\u0dd9\u0dba \u0dc3\u0d9a\u0dc3\u0dca \u0d9a\u0dbb\u0db1 \u0dbd\u0daf\u0dd3. </p>\n",
 "<p>Check to make sure the parameter is not sharing storage with anything else </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0dc0\u0dd9\u0db1\u0dad\u0dca \u0d9a\u0dd2\u0dc3\u0dd2\u0dc0\u0d9a\u0dca \u0dc3\u0db8\u0d9f \u0d9c\u0db6\u0da9\u0dcf \u0db6\u0dd9\u0daf\u0dcf \u0db1\u0ddc\u0d9c\u0db1\u0dca\u0db1\u0dcf \u0db6\u0dc0\u0da7 \u0dc0\u0d9c \u0db6\u0dbd\u0dcf \u0d9c\u0db1\u0dca\u0db1 \u0db4\u0dbb\u0dd3\u0d9a\u0dca\u0dc2\u0dcf \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Clean the gradients </p>\n": "<p>\u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a\u0db4\u0dd2\u0dbb\u0dd2\u0dc3\u0dd2\u0daf\u0dd4 </p>\n",
 "<p>Cleanup the normal parameters </p>\n": "<p>\u0dc3\u0dcf\u0db8\u0dcf\u0db1\u0dca\u0dba\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db4\u0dd2\u0dbb\u0dd2\u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Cleanup the parameters of the layer.</p>\n<p><em>Skip cleaning up if autograd is enabled and this is the last layer in the network, because we will need to fetch the parameters again for the backward pass.</em> </p>\n": "<p>\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db4\u0dd2\u0dbb\u0dd2\u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1. </p>\n<p><em>\u0d94\u0da7\u0ddd\u0d9c\u0dca\u0dbb\u0dcf\u0da9\u0dca\u0dc3\u0d9a\u0dca\u0dbb\u0dd3\u0dba \u0d9a\u0dbb \u0d87\u0dad\u0dca\u0db1\u0db8\u0dca \u0db4\u0dd2\u0dbb\u0dd2\u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0db8\u0d9f \u0dc4\u0dbb\u0dd2\u0db1\u0dca\u0db1, \u0db8\u0dd9\u0dba \u0da2\u0dcf\u0dbd\u0dba\u0dda \u0d85\u0dc0\u0dc3\u0dcf\u0db1 \u0dc3\u0dca\u0dad\u0dbb\u0dba \u0dc0\u0dda, \u0db8\u0db1\u0dca\u0daf \u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3 \u0db4\u0dcf\u0dc3\u0dca \u0dc3\u0db3\u0dc4\u0dcf \u0d85\u0db4\u0da7 \u0db1\u0dd0\u0dc0\u0dad \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0db6\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8\u0da7 \u0d85\u0dc0\u0dc1\u0dca\u0dba \u0dc0\u0db1\u0dd4 \u0d87\u0dad. </em> </p>\n",
 "<p>Collect all the parameters of the layer </p>\n": "<p>\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda\u0dc3\u0dd2\u0dba\u0dbd\u0dd4 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Collect gradients </p>\n": "<p>\u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a\u0d91\u0d9a\u0dad\u0dd4 </p>\n",
 "<p>Collect the chunk data </p>\n": "<p>\u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2\u0dba\u0daf\u0dad\u0dca\u0dad \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Collect the individual parameter tensors </p>\n": "<p>\u0dad\u0db1\u0dd2\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2 \u0d86\u0dad\u0dad\u0dd3\u0db1\u0dca \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Compute the outputs of the current layer </p>\n": "<p>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0db4\u0dca\u0dbb\u0dad\u0dd2\u0daf\u0dcf\u0db1\u0dba\u0db1\u0dca \u0d9c\u0dab\u0db1\u0dba \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Concatenate all the parameters and pad it </p>\n": "<p>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db8\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0d82\u0dba\u0dd4\u0d9a\u0dca\u0dad \u0d9a\u0dbb \u0d91\u0dba \u0db4\u0dd1\u0da9\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Concatenate both trainable and fixed chunks </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2 \u0daf\u0dd9\u0d9a\u0db8 \u0dc3\u0d82\u0dba\u0dd4\u0d9a\u0dca\u0dad \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Concatenate both trainable and fixed params </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dca \u0daf\u0dd9\u0d9a\u0db8 \u0dc3\u0d82\u0dba\u0dd4\u0d9a\u0dca\u0dad \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Create an empty padding tensor </p>\n": "<p>\u0dc4\u0dd2\u0dc3\u0dca\u0db4\u0dd4\u0dbb\u0dc0\u0db1 tensor \u0dc3\u0dcf\u0daf\u0db1\u0dca\u0db1 </p>\n",
 "<p>Create an empty tensor to receive the parameters </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0dbd\u0db6\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0dc4\u0dd2\u0dc3\u0dca \u0da7\u0dd9\u0db1\u0dca\u0dc3\u0dbb\u0dba\u0d9a\u0dca \u0dc3\u0dcf\u0daf\u0db1\u0dca\u0db1 </p>\n",
 "<p>Create an empty tensor to receive the sizes </p>\n": "<p>\u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0dbd\u0db6\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0dc4\u0dd2\u0dc3\u0dca \u0da7\u0dd9\u0db1\u0dca\u0dc3\u0dbb\u0dba\u0d9a\u0dca \u0dc3\u0dcf\u0daf\u0db1\u0dca\u0db1 </p>\n",
 "<p>Create parameters for trainable (<span translate=no>_^_0_^_</span>) and fixed (<span translate=no>_^_1_^_</span>) parameters to be stored in current device/node </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 (<span translate=no>_^_0_^_</span>) \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb (<span translate=no>_^_1_^_</span>) \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0db3\u0dc4\u0dcf \u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca \u0d8b\u0db4\u0dcf\u0d82\u0d9c\u0dba\u0dda/\u0db1\u0ddd\u0da9\u0dba\u0dda \u0d9c\u0db6\u0da9\u0dcf \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0dcf\u0daf\u0db1\u0dca\u0db1 </p>\n",
 "<p>Data type of the layer </p>\n": "<p>\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda\u0daf\u0dad\u0dca\u0dad \u0dc0\u0dbb\u0dca\u0d9c\u0dba </p>\n",
 "<p>Decrement the hooks counter </p>\n": "<p>\u0d9a\u0ddc\u0d9a\u0dd4\u0d9a\u0dc0\u0dd4\u0db1\u0dca\u0da7\u0dbb\u0dba \u0d85\u0da9\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 </p>\n",
 "<p>Device of the layer </p>\n": "<p>\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda\u0d8b\u0db4\u0dcf\u0d82\u0d9c\u0dba </p>\n",
 "<p>Each shard keeps parameters in <span translate=no>_^_0_^_</span> list. The <span translate=no>_^_1_^_</span> is for trainable parameters and <span translate=no>_^_2_^_</span> is for fixed parameters. </p>\n": "<p>\u0dc3\u0dd1\u0db8\u0d9a\u0ddc\u0da7\u0dc3\u0d9a\u0dca\u0db8 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca <span translate=no>_^_0_^_</span> \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0\u0dda \u0dad\u0db6\u0dcf \u0d9c\u0db1\u0dd3. \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0db3\u0dc4\u0dcf <span translate=no>_^_1_^_</span> <span translate=no>_^_2_^_</span> \u0dc0\u0db1 \u0d85\u0dad\u0dbb \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0db3\u0dc4\u0dcf \u0dc0\u0dda. </p>\n",
 "<p>Empty tensor to accumulate the gradients of the current shard </p>\n": "<p>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0dc2\u0dcf\u0dbb\u0dca\u0da9\u0dca \u0dc0\u0dbd \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0dc3\u0db8\u0dd4\u0da0\u0dca\u0da0\u0dba \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0dc4\u0dd2\u0dc3\u0dca \u0da7\u0dd9\u0db1\u0dca\u0dc3\u0dbb\u0dba </p>\n",
 "<p>Fetch all the parameters of the current node. This gets called by the previous layer so this call is just to make sure parameters are fetched. </p>\n": "<p>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0db1\u0ddd\u0da9\u0dba\u0dda \u0dc3\u0dd2\u0dba\u0dbd\u0dd4 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1. \u0db8\u0dd9\u0dba \u0db4\u0dd9\u0dbb \u0dc3\u0dca\u0dad\u0dbb\u0dba \u0db8\u0d9c\u0dd2\u0db1\u0dca \u0d9a\u0dd0\u0db3\u0dc0\u0db1\u0dd4 \u0dbd\u0dd0\u0db6\u0dda, \u0d91\u0db6\u0dd0\u0dc0\u0dd2\u0db1\u0dca \u0db8\u0dd9\u0db8 \u0d87\u0db8\u0dad\u0dd4\u0db8 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0db6\u0dcf \u0d9c\u0dad \u0dc4\u0dd0\u0d9a\u0dd2 \u0db6\u0dc0\u0da7 \u0dc0\u0d9c \u0db6\u0dbd\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0db4\u0db8\u0dab\u0dd2. </p>\n",
 "<p>Forward pass </p>\n": "<p>\u0d89\u0daf\u0dd2\u0dbb\u0dd2\u0dc3\u0dcf\u0db8\u0dcf\u0dbb\u0dca\u0dae\u0dba </p>\n",
 "<p>Gather the parameters from all the nodes/devices </p>\n": "<p>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db8\u0db1\u0ddd\u0da9\u0dca/\u0d8b\u0db4\u0dcf\u0d82\u0d9c \u0dc0\u0dbd\u0dd2\u0db1\u0dca \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0d91\u0d9a\u0dca\u0dbb\u0dd0\u0dc3\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Get a handle to add the backward hook. <a href=\"https://amsword.medium.com/understanding-pytorchs-autograd-with-grad-fn-and-next-functions-b2c4836daa00\">This blog discusses about <span translate=no>_^_0_^_</span></a>. </p>\n": "<p>\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3\u0d9a\u0ddc\u0d9a\u0dca\u0d9a \u0d91\u0d9a\u0dca \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0dc4\u0dc3\u0dd4\u0dbb\u0dd4\u0dc0 \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1. <a href=\"https://amsword.medium.com/understanding-pytorchs-autograd-with-grad-fn-and-next-functions-b2c4836daa00\">\u0db8\u0dd9\u0db8 \u0db6\u0dca\u0dbd\u0ddc\u0d9c\u0dca \u0d85\u0da9\u0dc0\u0dd2\u0dba \u0d9c\u0dd0\u0db1 \u0dc3\u0dcf\u0d9a\u0da0\u0dca\u0da1\u0dcf \u0d9a\u0dbb\u0dba\u0dd2 <span translate=no>_^_0_^_</span></a>. </p>\n",
 "<p>Handle a backward event </p>\n": "<p>\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3\u0dc3\u0dd2\u0daf\u0dd4\u0dc0\u0dd3\u0db8\u0d9a\u0dca \u0dc4\u0dc3\u0dd4\u0dbb\u0dd4\u0dc0\u0db1\u0dca\u0db1 </p>\n",
 "<p>If all the hooks (including the module hook) have been called, then we can back up gradients and clean up the parameters. </p>\n": "<p>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db8\u0d9a\u0ddc\u0d9a\u0dd4 (\u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd \u0d9a\u0ddc\u0d9a\u0dca\u0d9a \u0d87\u0dad\u0dd4\u0dc5\u0dd4\u0dc0) \u0d9a\u0dd0\u0db3\u0dc0\u0dcf \u0d87\u0dad\u0dca\u0db1\u0db8\u0dca, \u0d85\u0db4\u0da7 \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0d8b\u0db4\u0dc3\u0dca\u0dae \u0d9a\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db4\u0dd2\u0dbb\u0dd2\u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2\u0dba. </p>\n",
 "<p>If it is not divisible by <span translate=no>_^_0_^_</span>, pad it </p>\n": "<p>\u0d91\u0dba\u0db6\u0dd9\u0daf\u0dd2\u0dba \u0db1\u0ddc\u0dc4\u0dd0\u0d9a\u0dd2 \u0db1\u0db8\u0dca <span translate=no>_^_0_^_</span>, \u0d91\u0dba \u0db4\u0dd1\u0da9\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>If there are no parameters, skip </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0db1\u0ddc\u0db8\u0dd0\u0dad\u0dd2 \u0db1\u0db8\u0dca, \u0db8\u0d9f \u0dc4\u0dbb\u0dd2\u0db1\u0dca\u0db1 </p>\n",
 "<p>Increment the number of hooks added </p>\n": "<p>\u0d91\u0d9a\u0dad\u0dd4\u0d9a\u0dbb\u0db1 \u0dbd\u0daf \u0d9a\u0ddc\u0d9a\u0dd4 \u0d9c\u0dab\u0db1 \u0dc0\u0dd0\u0da9\u0dd2 \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Initialize the properties </p>\n": "<p>\u0d9c\u0dd4\u0dab\u0dcf\u0d82\u0d9c\u0d86\u0dbb\u0db8\u0dca\u0db7 \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Iterate through all parameters </p>\n": "<p>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc4\u0dbb\u0dc4\u0dcf \u0db1\u0dd0\u0dc0\u0dad </p>\n",
 "<p>Iterate through model parameters and assign the values from the continuous tensor </p>\n": "<p>\u0d86\u0daf\u0dbb\u0dca\u0dc1\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc4\u0dbb\u0dc4\u0dcf \u0db1\u0dd0\u0dc0\u0dad \u0db1\u0dd0\u0dc0\u0dad\u0dad\u0dca \u0dc3\u0dc4 \u0d85\u0d9b\u0dab\u0dca\u0da9 tensor \u0dc3\u0dd2\u0da7 \u0d85\u0d9c\u0dba\u0db1\u0dca \u0db4\u0dd0\u0dc0\u0dbb\u0dd3\u0db8 </p>\n",
 "<p>Iterate through trainable parameters </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc4\u0dbb\u0dc4\u0dcf \u0db1\u0dd0\u0dc0\u0dad \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Keep a reference to the handle </p>\n": "<p>\u0dc4\u0dc3\u0dd4\u0dbb\u0dd4\u0dc0\u0d9c\u0dd0\u0db1 \u0dc3\u0db3\u0dc4\u0db1\u0d9a\u0dca \u0dad\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1 </p>\n",
 "<p>List of layers right after this layer </p>\n": "<p>\u0db8\u0dd9\u0db8\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0da7 \u0db4\u0dc3\u0dd4\u0dc0 \u0dc3\u0dca\u0dae\u0dbb \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0 </p>\n",
 "<p>List of layers right before this layer </p>\n": "<p>\u0db8\u0dd9\u0db8\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0da7 \u0db4\u0dd9\u0dbb \u0dc3\u0dca\u0dae\u0dbb \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0 </p>\n",
 "<p>Loop through trainable parameters of the current layer </p>\n": "<p>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc4\u0dbb\u0dc4\u0dcf \u0dbd\u0dd6\u0db4\u0dca </p>\n",
 "<p>Make sure a hook hasn&#x27;t already been added </p>\n": "<p>\u0d9a\u0ddc\u0d9a\u0dca\u0d9a\u0d9a\u0dca\u0daf\u0dd0\u0db1\u0da7\u0db8\u0dad\u0dca \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb \u0db1\u0ddc\u0db8\u0dd0\u0dad\u0dd2 \u0db6\u0dc0\u0da7 \u0dc0\u0d9c \u0db6\u0dbd\u0dcf \u0d9c\u0db1\u0dca\u0db1 </p>\n",
 "<p>Make sure gradient back up is complete </p>\n": "<p>\u0d86\u0db4\u0dc3\u0dd4\u0daf\u0d9a\u0dca\u0dc0\u0dcf \u0db5\u0dbd\u0dba \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0dc3\u0db8\u0dca\u0db4\u0dd6\u0dbb\u0dca\u0dab \u0db6\u0dc0\u0da7 \u0dc0\u0d9c \u0db6\u0dbd\u0dcf \u0d9c\u0db1\u0dca\u0db1 </p>\n",
 "<p>Make sure the parameter has no gradient data </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0da7\u0dc1\u0dca\u0dbb\u0dda\u0dab\u0dd2\u0dba\u0dda \u0daf\u0dad\u0dca\u0dad \u0db1\u0ddc\u0db8\u0dd0\u0dad\u0dd2 \u0db6\u0dc0\u0da7 \u0dc0\u0d9c \u0db6\u0dbd\u0dcf \u0d9c\u0db1\u0dca\u0db1 </p>\n",
 "<p>Merge and pad trainable (<span translate=no>_^_0_^_</span>) and fixed (<span translate=no>_^_1_^_</span>) parameters </p>\n": "<p>\u0d92\u0d9a\u0dcf\u0db6\u0daf\u0dca\u0db0\u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0dc3\u0dc4 \u0db4\u0dd1\u0da9\u0dca \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 (<span translate=no>_^_0_^_</span>) \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb (<span translate=no>_^_1_^_</span>) \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca </p>\n",
 "<p>Number of backward hooks added </p>\n": "<p>\u0db4\u0dc3\u0dd4\u0d9c\u0dcf\u0db8\u0dd3\u0d9a\u0ddc\u0d9a\u0dd4 \u0d9c\u0dab\u0db1 \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb\u0db1 \u0dbd\u0daf\u0dd2 </p>\n",
 "<p>Number of nodes/devices the data is sharded across </p>\n": "<p>\u0db1\u0ddd\u0da9\u0dca/\u0d8b\u0db4\u0dcf\u0d82\u0d9c\u0d9c\u0dab\u0db1 \u0daf\u0dad\u0dca\u0dad \u0dc4\u0dbb\u0dc4\u0dcf \u0dad\u0dd2\u0dba\u0dd4\u0dab\u0dd4 \u0dc0\u0dda </p>\n",
 "<p>Offset of the continuous buffer </p>\n": "<p>\u0d85\u0d9b\u0dab\u0dca\u0da9\u0db6\u0dc6\u0dbb\u0dba\u0dda \u0d95\u0dc6\u0dca\u0dc3\u0dd9\u0da7\u0dca </p>\n",
 "<p>Offset of the continuous tensor </p>\n": "<p>\u0d85\u0d9b\u0dab\u0dca\u0da9\u0d86\u0dad\u0dad\u0dd2\u0dba\u0dd9\u0db1\u0dca \u0d95\u0dc6\u0dca\u0dc3\u0dd9\u0da7\u0dca </p>\n",
 "<p>Original parameter shape </p>\n": "<p>\u0db8\u0dd4\u0dbd\u0dca\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2 \u0dc4\u0dd0\u0da9\u0dba </p>\n",
 "<p>Otherwise, no need to pad </p>\n": "<p>\u0d91\u0dc3\u0dda\u0db1\u0ddc\u0db8\u0dd0\u0dad\u0dd2 \u0db1\u0db8\u0dca, \u0db4\u0dd1\u0da9\u0dca \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0d85\u0dc0\u0dc1\u0dca\u0dba \u0db1\u0dd0\u0dad </p>\n",
 "<p>Receive the parameters </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1 </p>\n",
 "<p>Receive the sizes </p>\n": "<p>\u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1 </p>\n",
 "<p>Remove the handle from the parameter </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0dd9\u0db1\u0dca\u0dc4\u0dc3\u0dd4\u0dbb\u0dd4\u0dc0 \u0d89\u0dc0\u0dad\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Reshape the trainable and fixed parameters to continuous tensors </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0d85\u0d9b\u0dab\u0dca\u0da9 \u0d86\u0dad\u0dad\u0dd3\u0db1\u0dca\u0da7 \u0db1\u0dd0\u0dc0\u0dad \u0dc3\u0d9a\u0dc3\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Resize the storage to <span translate=no>_^_0_^_</span>. This will release the memory used by the parameter.</p>\n<p><strong>Setting <span translate=no>_^_1_^_</span> will not release the memory, since the autograd graph keeps a reference to it.</strong> </p>\n": "<p>\u0d9c\u0db6\u0da9\u0dcf\u0dc0\u0dc0\u0dd9\u0db1\u0dc3\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 <span translate=no>_^_0_^_</span>. \u0db8\u0dd9\u0dba \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db1 \u0db8\u0dad\u0d9a\u0dba \u0db8\u0dd4\u0daf\u0dcf \u0dc4\u0dbb\u0dd2\u0db1\u0dd4 \u0d87\u0dad. </p>\n<p><strong>\u0dc3\u0dca\u0dc0\u0dba\u0d82\u0d9a\u0dca\u200d\u0dbb\u0dd3\u0dba\u0db4\u0dca\u200d\u0dbb\u0dc3\u0dca\u0dad\u0dcf\u0dbb\u0dba \u0d92 \u0db4\u0dd2\u0dc5\u0dd2\u0db6\u0db3\u0dc0 \u0dc3\u0db3\u0dc4\u0db1\u0d9a\u0dca \u0dad\u0db6\u0dcf \u0d87\u0dad\u0dd2 \u0db6\u0dd0\u0dc0\u0dd2\u0db1\u0dca \u0dc3\u0dd0\u0d9a\u0dc3\u0dd4\u0db8 \u0db8\u0dad\u0d9a\u0dba \u0db8\u0dd4\u0daf\u0dcf <span translate=no>_^_1_^_</span> \u0db1\u0ddc\u0dc4\u0dbb\u0dd2\u0db1\u0dd4 \u0d87\u0dad. </strong> </p>\n",
 "<p>Return and empty list if there are no trainable parameters </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db1\u0ddc\u0db8\u0dd0\u0dad\u0dd2 \u0db1\u0db8\u0dca \u0d86\u0db4\u0dc3\u0dd4 \u0dc3\u0dc4 \u0dc4\u0dd2\u0dc3\u0dca \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0 </p>\n",
 "<p>Return the list of trainable chunks from each layer </p>\n": "<p>\u0d91\u0d9a\u0dca\u0d91\u0d9a\u0dca \u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dd9\u0db1\u0dca \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2 \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0 \u0d86\u0db4\u0dc3\u0dd4 \u0dbd\u0db6\u0dcf \u0daf\u0dd9\u0db1\u0dca\u0db1 </p>\n",
 "<p>Return the trainable chunk as a list </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2\u0dba \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0\u0d9a\u0dca \u0dbd\u0dd9\u0dc3 \u0d86\u0db4\u0dc3\u0dd4 \u0d91\u0dc0\u0db1\u0dca\u0db1 </p>\n",
 "<p>Scatter them to all the nodes/devices </p>\n": "<p>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db8\u0db1\u0ddd\u0da9\u0dca/\u0d8b\u0db4\u0dcf\u0d82\u0d9c \u0dc0\u0dd9\u0dad \u0d92\u0dc0\u0dcf \u0dc0\u0dd2\u0dc3\u0dd4\u0dbb\u0dd4\u0dc0\u0dcf \u0dc4\u0dbb\u0dd2\u0db1\u0dca\u0db1 </p>\n",
 "<p>Separate parameters as trainable and fixed </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0dbd\u0dd9\u0dc3 \u0dc0\u0dd9\u0db1\u0db8 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca </p>\n",
 "<p>Set layer index </p>\n": "<p>\u0dc3\u0dca\u0dae\u0dbb\u0daf\u0dbb\u0dca\u0dc1\u0d9a\u0dba \u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1 </p>\n",
 "<p>Set preceding layers </p>\n": "<p>\u0db4\u0dd9\u0dbb\u0dc3\u0dca\u0dae\u0dbb \u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1 </p>\n",
 "<p>Set proceeding layers </p>\n": "<p>\u0d89\u0daf\u0dd2\u0dbb\u0dd2\u0dba\u0da7\u0dba\u0db1 \u0dc3\u0dca\u0dae\u0dbb \u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1 </p>\n",
 "<p>Set streams </p>\n": "<p>\u0db0\u0dcf\u0dbb\u0dcf\u0dc0\u0db1\u0dca\u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1 </p>\n",
 "<p>Set the chunk gradients. This is what the optimizer sees. </p>\n": "<p>\u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2\u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1. \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0d9a\u0dbb\u0dab\u0dba \u0daf\u0d9a\u0dd2\u0db1\u0dca\u0db1\u0dda \u0db8\u0dd9\u0dba\u0dba\u0dd2. </p>\n",
 "<p>Set the flag </p>\n": "<p>\u0db0\u0da2\u0dba\u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1 </p>\n",
 "<p>Set the flag to indicate that the parameters are not fetched </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0dbd\u0db6\u0dcf \u0d9c\u0dad \u0db1\u0ddc\u0dc4\u0dd0\u0d9a\u0dd2 \u0db6\u0dc0 \u0daf\u0dd0\u0d9a\u0dca\u0dc0\u0dd3\u0db8\u0da7 \u0db0\u0da2\u0dba \u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1 </p>\n",
 "<p>Set the streams and preceding and proceeding layers for each <span translate=no>_^_0_^_</span> layer </p>\n": "<p>\u0d91\u0d9a\u0dca\u0d91\u0d9a\u0dca <span translate=no>_^_0_^_</span> \u0dc3\u0dca\u0dae\u0dbb\u0dba\u0d9a\u0dca \u0dc3\u0db3\u0dc4\u0dcf \u0db0\u0dcf\u0dbb\u0dcf\u0dc0\u0db1\u0dca \u0dc3\u0dc4 \u0db4\u0dd9\u0dbb \u0dc3\u0dc4 \u0d89\u0daf\u0dd2\u0dbb\u0dd2\u0dba\u0da7 \u0dba\u0db1 \u0dc3\u0dca\u0dae\u0dbb \u0dc3\u0d9a\u0dc3\u0db1\u0dca\u0db1 </p>\n",
 "<p>Skip if there are no trainable parameters </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db1\u0ddc\u0db8\u0dd0\u0dad\u0dd2 \u0db1\u0db8\u0dca \u0db8\u0d9f \u0dc4\u0dbb\u0dd2\u0db1\u0dca\u0db1 </p>\n",
 "<p>Skip if there&#x27;s nothing to fetch or share. </p>\n": "\u0dbd\u0db6\u0dcf<p>\u0d9c\u0dd0\u0db1\u0dd3\u0db8\u0da7 \u0dc4\u0ddd \u0db6\u0dd9\u0daf\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8\u0da7 \u0d9a\u0dd2\u0dc3\u0dd2\u0dc0\u0d9a\u0dca \u0db1\u0ddc\u0db8\u0dd0\u0dad\u0dd2 \u0db1\u0db8\u0dca \u0db8\u0d9f \u0dc4\u0dbb\u0dd2\u0db1\u0dca\u0db1. </p>\n",
 "<p>Skip is already fetched </p>\n": "<p>\u0db8\u0d9f\u0dc4\u0dd0\u0dbb\u0dd3\u0db8 \u0daf\u0dd0\u0db1\u0da7\u0db8\u0dad\u0dca \u0dbd\u0dd0\u0db6\u0dd3 \u0d87\u0dad </p>\n",
 "<p>Split the continuous buffer into number of nodes. These splits are views of `buffer&#x27;. </p>\n": "<p>\u0d85\u0d9b\u0dab\u0dca\u0da9\u0db6\u0dc6\u0dbb\u0dba \u0db1\u0ddd\u0da9\u0dca \u0d9c\u0dab\u0db1\u0d9a\u0da7 \u0db6\u0dd9\u0daf\u0db1\u0dca\u0db1. \u0db8\u0dd9\u0db8 \u0db6\u0dd9\u0daf\u0dd3\u0db8\u0dca `\u0db6\u0dc6\u0dbb\u0dca' \u0db4\u0dd2\u0dc5\u0dd2\u0db6\u0db3 \u0d85\u0daf\u0dc4\u0dc3\u0dca \u0dc0\u0dda. </p>\n",
 "<p>Split the continuous buffer into the number of nodes. These splits are views of `buffer&#x27;. </p>\n": "<p>\u0d85\u0d9b\u0dab\u0dca\u0da9\u0db6\u0dc6\u0dbb\u0dba \u0db1\u0ddd\u0da9\u0dca \u0d9c\u0dab\u0db1\u0da7 \u0db6\u0dd9\u0daf\u0db1\u0dca\u0db1. \u0db8\u0dd9\u0db8 \u0db6\u0dd9\u0daf\u0dd3\u0db8\u0dca `\u0db6\u0dc6\u0dbb\u0dca' \u0db4\u0dd2\u0dc5\u0dd2\u0db6\u0db3 \u0d85\u0daf\u0dc4\u0dc3\u0dca \u0dc0\u0dda. </p>\n",
 "<p>Split the gathered parameters into the trainable and fixed chunks </p>\n": "<p>\u0dbb\u0dd0\u0dc3\u0dca\u0d9a\u0dbb\u0db1 \u0dbd\u0daf \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2 \u0dc0\u0dbd\u0da7 \u0db6\u0dd9\u0daf\u0db1\u0dca\u0db1 </p>\n",
 "<p>Start fetch parameters of the previous layer, because autograd will next process the gradients of it. </p>\n": "<p>\u0db4\u0dd9\u0dbb\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0db6\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8 \u0d86\u0dbb\u0db8\u0dca\u0db7 \u0d9a\u0dbb\u0db1\u0dca\u0db1, \u0db8\u0db1\u0dca\u0daf \u0d94\u0da7\u0ddd\u0d9c\u0dca\u0dbb\u0dcf\u0da9\u0dca \u0d8a\u0dc5\u0d9f\u0da7 \u0d91\u0dc4\u0dd2 \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dc0\u0dbd\u0dd2\u0dba \u0d9a\u0dbb\u0db1\u0dd4 \u0d87\u0dad. </p>\n",
 "<p>Start fetching parameters of the proceeding layers, so that they will fetch them which the current layer does its computations. </p>\n": "<p>\u0d89\u0daf\u0dd2\u0dbb\u0dd2\u0dba\u0da7\u0dba\u0db1 \u0dc3\u0dca\u0dae\u0dbb\u0dc0\u0dbd \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0db6\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8 \u0d86\u0dbb\u0db8\u0dca\u0db7 \u0d9a\u0dbb\u0db1\u0dca\u0db1, \u0d91\u0dc0\u0dd2\u0da7 \u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca \u0dc3\u0dca\u0dad\u0dbb\u0dba \u0d91\u0dc4\u0dd2 \u0d9c\u0dab\u0db1\u0dba \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0dca \u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dbb\u0db1 \u0d92\u0dc0\u0dcf \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dd4 \u0d87\u0dad. </p>\n",
 "<p>Store list of modules </p>\n": "<p>\u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0d9c\u0db6\u0da9\u0dcf \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0 </p>\n",
 "<p>Store the shape of the parameters because we need it later to reconstruct them </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0d9c\u0dda\u0dc4\u0dd0\u0da9\u0dba \u0d9c\u0db6\u0da9\u0dcf \u0d9a\u0dbb \u0dad\u0db6\u0db1\u0dca\u0db1, \u0db8\u0db1\u0dca\u0daf \u0d92\u0dc0\u0dcf \u0db4\u0dca\u0dbb\u0dad\u0dd2\u0db1\u0dd2\u0dbb\u0dca\u0db8\u0dcf\u0dab\u0dba \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0d85\u0db4\u0da7 \u0db4\u0dc3\u0dd4\u0dc0 \u0d85\u0dc0\u0dc1\u0dca\u0dba \u0dc0\u0dda </p>\n",
 "<p>The <span translate=no>_^_0_^_</span> node will calculate the size each device/node should store, and distribute the parameters accordingly. </p>\n": "<p>\u0db8\u0dd9\u0db8 <span translate=no>_^_0_^_</span> \u0db1\u0ddd\u0da9\u0dba \u0d91\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0d8b\u0db4\u0dcf\u0d82\u0d9c\u0dba/\u0db1\u0ddd\u0da9\u0dba \u0d9c\u0db6\u0da9\u0dcf \u0d9a\u0dc5 \u0dba\u0dd4\u0dad\u0dd4 \u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0dba \u0d9c\u0dab\u0db1\u0dba \u0d9a\u0dbb\u0db1\u0dd4 \u0d87\u0dad, \u0d92 \u0d85\u0db1\u0dd4\u0dc0 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0db6\u0dd9\u0daf\u0dcf \u0dc4\u0dbb\u0dd2\u0db1\u0dd4 \u0d87\u0dad. </p>\n",
 "<p>The first chunk is for trainable parameters. </p>\n": "<p>\u0db4\u0dc5\u0db8\u0dd4\u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2\u0dba \u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dc3\u0db3\u0dc4\u0dcf \u0dc0\u0dda. </p>\n",
 "<p>The module to be wrapped </p>\n": "<p>\u0d91\u0dc0\u0dd2\u0dba\u0dba\u0dd4\u0dad\u0dd4 \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba </p>\n",
 "<p>The position of the current layer; used this for debugging logs </p>\n": "<p>\u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca\u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0db4\u0dd2\u0dc4\u0dd2\u0da7\u0dd3\u0db8; \u0dbd\u0d9d\u0dd4-\u0dc3\u0da7\u0dc4\u0db1\u0dca \u0db1\u0dd2\u0daf\u0ddc\u0dc3\u0dca\u0d9a\u0dbb\u0dab\u0dba \u0dc3\u0db3\u0dc4\u0dcf \u0db8\u0dd9\u0dba \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0dba\u0dd2 </p>\n",
 "<p>The previous layer will start computing gradients. We need to make sure it has finished fetching params. </p>\n": "<p>\u0db4\u0dd9\u0dbb\u0dc3\u0dca\u0dae\u0dbb\u0dba \u0db4\u0dbb\u0dd2\u0d9c\u0dab\u0d9a \u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a \u0d86\u0dbb\u0db8\u0dca\u0db7 \u0dc0\u0db1\u0dd4 \u0d87\u0dad. \u0d91\u0dba \u0db4\u0dbb\u0dcf\u0db8\u0dca \u0dbd\u0db6\u0dcf \u0d9c\u0dd0\u0db1\u0dd3\u0db8 \u0d85\u0dc0\u0dc3\u0db1\u0dca \u0d9a\u0dbb \u0d87\u0dad\u0dd2 \u0db6\u0dc0\u0da7 \u0d85\u0db4 \u0dc0\u0d9c \u0db6\u0dbd\u0dcf \u0d9c\u0dad \u0dba\u0dd4\u0dad\u0dd4\u0dba. </p>\n",
 "<p>This is the list of parameters split into lists as trainable and fixed parameters. </p>\n": "<p>\u0db4\u0dd4\u0dc4\u0dd4\u0dab\u0dd4\u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dc4 \u0dc3\u0dca\u0dae\u0dcf\u0dc0\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0dd9\u0dc3 \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4 \u0dc0\u0dbd\u0da7 \u0db6\u0dd9\u0daf\u0dd3 \u0d87\u0dad\u0dd2 \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2 \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0 \u0db8\u0dd9\u0dba\u0dba\u0dd2. </p>\n",
 "<p>This is the sizes of the chunks in <span translate=no>_^_0_^_</span> list. </p>\n": "<p><span translate=no>_^_0_^_</span> \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0\u0dda \u0d87\u0dad\u0dd2 \u0d9a\u0dd4\u0da7\u0dca\u0da7\u0dd2 \u0dc0\u0dbd \u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0dba \u0db8\u0dd9\u0dba\u0dba\u0dd2. </p>\n",
 "<p>Total number of parameters </p>\n": "<p>\u0db8\u0dd4\u0dc5\u0dd4\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0d9c\u0dab\u0db1 </p>\n",
 "<p>Update the offset </p>\n": "<p>\u0d95\u0dc6\u0dca\u0dc3\u0dd9\u0da7\u0dca\u0dba\u0dcf\u0dc0\u0dad\u0dca\u0d9a\u0dcf\u0dbd\u0dd3\u0db1 \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Use <span translate=no>_^_0_^_</span> to create an autograd step which we can intercept </p>\n": "<p>\u0d85\u0db4\u0da7\u0db6\u0dcf\u0db0\u0dcf \u0d9a\u0dc5 \u0dc4\u0dd0\u0d9a\u0dd2 \u0dc3\u0dca\u0dc0\u0dba\u0d82\u0d9a\u0dca\u0dbb\u0dd3\u0dba \u0db4\u0dd2\u0dba\u0dc0\u0dbb\u0d9a\u0dca \u0db1\u0dd2\u0dbb\u0dca\u0db8\u0dcf\u0dab\u0dba <span translate=no>_^_0_^_</span> \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Use <span translate=no>_^_0_^_</span> to fetch the parameters from all the shards </p>\n": "<p>\u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0d9a\u0dd0\u0db6\u0dbd\u0dd2 \u0dc0\u0dbd\u0dd2\u0db1\u0dca \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca \u0dbd\u0db6\u0dcf <span translate=no>_^_0_^_</span> \u0d9c\u0dd0\u0db1\u0dd3\u0db8\u0da7 \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Use the backup stream to backup the gradients </p>\n": "<p>\u0d85\u0db1\u0dd4\u0d9a\u0dca\u0dbb\u0db8\u0dd2\u0d9a\u0d8b\u0db4\u0dc3\u0dca\u0dae \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0d8b\u0db4\u0dc3\u0dca\u0dae \u0db0\u0dcf\u0dbb\u0dcf\u0dc0 \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Wait for operations on the parameters to complete before any new operations </p>\n": "<p>\u0db1\u0dc0\u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8\u0dca \u0dc0\u0dbd\u0da7 \u0db4\u0dd9\u0dbb \u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0d9c\u0dda \u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8\u0dca \u0dc3\u0db8\u0dca\u0db4\u0dd6\u0dbb\u0dca\u0dab \u0dc0\u0db1 \u0dad\u0dd9\u0d9a\u0dca \u0dbb\u0dd0\u0db3\u0dd3 \u0dc3\u0dd2\u0da7\u0dd2\u0db1\u0dca\u0db1 </p>\n",
 "<p>Wait for parameter fetching to complete. </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd2\u0dba\u0dc3\u0db8\u0dca\u0db4\u0dd6\u0dbb\u0dca\u0dab \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0dc3\u0db3\u0dc4\u0dcf \u0dbb\u0dd0\u0db3\u0dd3 \u0dc3\u0dd2\u0da7\u0dd2\u0db1\u0dca\u0db1. </p>\n",
 "<p>Wait for the gather operation to complete and then clear the references to the buffers </p>\n": "<p>\u0d91\u0d9a\u0dca\u0dbb\u0dd0\u0dc3\u0dca\u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0dda \u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8 \u0dc3\u0db8\u0dca\u0db4\u0dd6\u0dbb\u0dca\u0dab \u0dc0\u0db1 \u0dad\u0dd9\u0d9a\u0dca \u0dbb\u0dd0\u0db3\u0dd3 \u0dc3\u0dd2\u0da7\u0dd2\u0db1\u0dca\u0db1, \u0db4\u0dc3\u0dd4\u0dc0 \u0d85\u0dc0\u0dbb\u0ddd\u0db0\u0d9a \u0dc0\u0dd9\u0dad \u0dba\u0ddc\u0db8\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0dca \u0d89\u0dc0\u0dad\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Wait for the operation to complete and then clear the references to the buffers </p>\n": "<p>\u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8\u0dc3\u0db8\u0dca\u0db4\u0dd6\u0dbb\u0dca\u0dab \u0dc0\u0db1 \u0dad\u0dd9\u0d9a\u0dca \u0dbb\u0dd0\u0db3\u0dd3 \u0dc3\u0dd2\u0da7\u0dd2\u0db1\u0dca\u0db1, \u0db4\u0dc3\u0dd4\u0dc0 \u0d85\u0dc0\u0dbb\u0ddd\u0db0\u0d9a \u0dc0\u0dd9\u0dad \u0dba\u0ddc\u0db8\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0dca \u0d89\u0dc0\u0dad\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Wait for the operation to complete before other operations can be performed </p>\n": "<p>\u0dc0\u0dd9\u0db1\u0dad\u0dca\u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8\u0dca \u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0db4\u0dd9\u0dbb \u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8 \u0dc3\u0db8\u0dca\u0db4\u0dd6\u0dbb\u0dca\u0dab \u0dc0\u0db1 \u0dad\u0dd9\u0d9a\u0dca \u0dbb\u0dd0\u0db3\u0dd3 \u0dc3\u0dd2\u0da7\u0dd2\u0db1\u0dca\u0db1 </p>\n",
 "<p>Wait for the operations to complete before other operations can be performed </p>\n": "<p>\u0dc0\u0dd9\u0db1\u0dad\u0dca\u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8\u0dca \u0dc3\u0dd2\u0daf\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7 \u0db4\u0dd9\u0dbb \u0db8\u0dd9\u0dc4\u0dd9\u0dba\u0dd4\u0db8\u0dca \u0dc3\u0db8\u0dca\u0db4\u0dd6\u0dbb\u0dca\u0dab \u0dc0\u0db1 \u0dad\u0dd9\u0d9a\u0dca \u0dbb\u0dd0\u0db3\u0dd3 \u0dc3\u0dd2\u0da7\u0dd2\u0db1\u0dca\u0db1 </p>\n",
 "<p>Whether parameters have been fetched </p>\n": "<p>\u0db4\u0dbb\u0dcf\u0db8\u0dd2\u0dad\u0dd3\u0db1\u0dca\u0dbd\u0db6\u0dcf \u0d9c\u0dd9\u0db1 \u0dad\u0dd2\u0db6\u0dda\u0daf </p>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  List of <span translate=no>_^_1_^_</span> layers</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span> <span translate=no>_^_1_^_</span> \u0dc3\u0dca\u0dae\u0dbb \u0dbd\u0dd0\u0dba\u0dd2\u0dc3\u0dca\u0dad\u0dd4\u0dc0</li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  The module to be wrapped. </li>\n<li><span translate=no>_^_1_^_</span>  The rank of the current node. </li>\n<li><span translate=no>_^_2_^_</span>  The number of nodes/devices the data is sharded across. </li>\n<li><span translate=no>_^_3_^_</span>  The device of the layer. </li>\n<li><span translate=no>_^_4_^_</span>  The data type of the layer.</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span> \u0d94\u0dad\u0dcf \u0d9c\u0dad \u0dba\u0dd4\u0dad\u0dd4 \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba. </li>\n<li><span translate=no>_^_1_^_</span> \u0dc0\u0dad\u0dca\u0db8\u0db1\u0dca \u0db1\u0ddd\u0da9\u0dba\u0dda \u0db1\u0dd2\u0dbd\u0dba. </li>\n<li><span translate=no>_^_2_^_</span> \u0daf\u0dad\u0dca\u0dad \u0dc4\u0dbb\u0dc4\u0dcf \u0dad\u0dd2\u0dba\u0dd4\u0dab\u0dd4 \u0d9a\u0dbb \u0d87\u0dad\u0dd2 \u0db1\u0ddd\u0da9\u0dca/\u0d8b\u0db4\u0dcf\u0d82\u0d9c \u0d9c\u0dab\u0db1. </li>\n<li><span translate=no>_^_3_^_</span> \u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0d8b\u0db4\u0dcf\u0d82\u0d9c\u0dba. </li>\n<li><span translate=no>_^_4_^_</span> \u0dc3\u0dca\u0dae\u0dbb\u0dba\u0dda \u0daf\u0dad\u0dca\u0dad \u0dc0\u0dbb\u0dca\u0d9c\u0dba. </li></ul>\n",
 "This is an implementation of Zero-DP Memory Optimization written in PyTorch.": "\u0db8\u0dd9\u0dba PyTorch \u0dc4\u0dd2 \u0dbd\u0dd2\u0dba\u0dcf \u0d87\u0dad\u0dd2 \u0dc1\u0dd4\u0db1\u0dca\u0dba-\u0da9\u0dd3\u0db4\u0dd3 \u0db8\u0dad\u0d9a \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab\u0dba \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0dba\u0dd2.",
 "Zero-DP Memory Optimization": "\u0dc1\u0dd4\u0db1\u0dca\u0dba-\u0da9\u0dd3\u0db4\u0dd3 \u0db8\u0dad\u0d9a \u0db4\u0dca\u0dbb\u0dc1\u0dc3\u0dca\u0dad\u0dd2\u0d9a\u0dbb\u0dab\u0dba"
}