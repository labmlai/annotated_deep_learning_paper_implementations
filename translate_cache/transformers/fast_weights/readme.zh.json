{
 "<h1><a href=\"https://nn.labml.ai/transformers/fast_weights/index.html\">Fast weights transformer</a></h1>\n<p>This is an annotated implementation of the paper <a href=\"https://arxiv.org/abs/2102.11174\">Linear Transformers Are Secretly Fast Weight Memory Systems in PyTorch</a>.</p>\n<p>Here is the <a href=\"https://nn.labml.ai/transformers/fast_weights/index.html\">annotated implementation</a>. Here are <a href=\"https://nn.labml.ai/transformers/fast_weights/experiment.html\">the training code</a> and a notebook for training a fast weights transformer on the Tiny Shakespeare dataset.</p>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/transformers/fast_weights/experiment.ipynb\"><span translate=no>_^_0_^_</span></a> </p>\n": "<h1><a href=\"https://nn.labml.ai/transformers/fast_weights/index.html\">\u5feb\u901f\u79f0\u91cd\u53d8\u538b\u5668</a></h1>\n<p>\u8fd9\u662f <a href=\"https://arxiv.org/abs/2102.11174\">PyTorch \u4e2d\u300a\u7ebf\u6027\u53d8\u538b\u5668\u79d8\u5bc6\u5730\u662f\u5feb\u901f\u52a0\u6743\u5185\u5b58\u7cfb\u7edf\u300b\u4e00\u6587\u7684</a>\u5e26\u6ce8\u91ca\u7684\u5b9e\u73b0\u3002</p>\n<p>\u8fd9\u662f<a href=\"https://nn.labml.ai/transformers/fast_weights/index.html\">\u5e26\u6ce8\u91ca\u7684\u5b9e\u73b0</a>\u3002\u4ee5\u4e0b\u662f\u7528\u4e8e<a href=\"https://nn.labml.ai/transformers/fast_weights/experiment.html\">\u5728 Tiny Shakespeare \u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u5feb\u901f\u6743\u91cd\u8f6c\u6362\u5668\u7684\u8bad\u7ec3\u4ee3\u7801</a>\u548c\u4e00\u672c\u7b14\u8bb0\u672c\u3002</p>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/transformers/fast_weights/experiment.ipynb\"><span translate=no>_^_0_^_</span></a></p>\n",
 "Fast weights transformer": "\u5feb\u901f\u91cd\u91cf\u53d8\u538b\u5668"
}