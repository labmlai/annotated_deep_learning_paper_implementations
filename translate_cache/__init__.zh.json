{
 "<h1><a href=\"index.html\">Annotated Research Paper Implementations: Transformers, StyleGAN, Stable Diffusion, DDPM/DDIM, LayerNorm, Nucleus Sampling and more</a></h1>\n": "<h1><a href=\"index.html\">labml.ai \u5e26\u6ce8\u91ca\u7684 PyTorch \u7248\u8bba\u6587\u5b9e\u73b0</a></h1>\n",
 "<h2>Paper Implementations</h2>\n": "<h2>\u8bba\u6587\u5b9e\u73b0</h2>\n",
 "<h2>Translations</h2>\n": "<h2>\u7ffb\u8bd1</h2>\n",
 "<h3><strong><a href=\"https://nn.labml.ai\">English (original)</a></strong></h3>\n": "<h3><strong><a href=\"https://nn.labml.ai\">\u82f1\u8bed\uff08\u539f\u7248\uff09</a></strong></h3>\n",
 "<h3><strong><a href=\"https://nn.labml.ai/ja/\">Japanese (translated)</a></strong></h3>\n": "</a><h3><strong><a href=\"https://nn.labml.ai/ja/\">\u65e5\u8bed\uff08\u7ffb\u8bd1\uff09</strong></h3>\n",
 "<h3><strong><a href=\"https://nn.labml.ai/zh/\">Chinese (translated)</a></strong></h3>\n": "</a><h3><strong><a href=\"https://nn.labml.ai/zh/\">\u4e2d\u6587\uff08\u7ffb\u8bd1\uff09</strong></h3>\n",
 "<h3>Installation</h3>\n": "<h3>\u5b89\u88c5</h3>\n",
 "<h4>\u2728 <a href=\"activations/index.html\">Activations</a></h4>\n": "<h4>\u2728 <a href=\"activations/index.html\">\u6fc0\u6d3b\u51fd\u6570</a></h4>\n",
 "<h4>\u2728 <a href=\"adaptive_computation/index.html\">Adaptive Computation</a></h4>\n": "<h4>\u2728 <a href=\"adaptive_computation/index.html\">\u81ea\u9002\u5e94\u8ba1\u7b97</a></h4>\n",
 "<h4>\u2728 <a href=\"capsule_networks/index.html\">Capsule Networks</a></h4>\n": "<h4>\u2728 <a href=\"capsule_networks/index.html\">\u80f6\u56ca\u7f51\u7edc</a></h4>\n",
 "<h4>\u2728 <a href=\"cfr/index.html\">Counterfactual Regret Minimization (CFR)</a></h4>\n": "<h4>\u2728 <a href=\"cfr/index.html\">\u865a\u62df\u9057\u61be\u6700\u5c0f\u5316\uff08CFR\uff09</a></h4>\n",
 "<h4>\u2728 <a href=\"conv_mixer/index.html\">ConvMixer</a></h4>\n": "<h4>\u2728 <a href=\"conv_mixer/index.html\">ConvMixer</a></h4>\n",
 "<h4>\u2728 <a href=\"diffusion/index.html\">Diffusion models</a></h4>\n": "<h4>\u2728 <a href=\"diffusion/index.html\">\u6269\u6563\u6a21\u578b</a></h4>\n",
 "<h4>\u2728 <a href=\"distillation/index.html\">Distillation</a></h4>\n": "<h4>\u2728 <a href=\"distillation/index.html\">\u84b8\u998f</a></h4>\n",
 "<h4>\u2728 <a href=\"gan/index.html\">Generative Adversarial Networks</a></h4>\n": "<h4>\u2728 <a href=\"gan/index.html\">\u751f\u6210\u5bf9\u6297\u7f51\u7edc</a></h4>\n",
 "<h4>\u2728 <a href=\"hypernetworks/hyper_lstm.html\">HyperNetworks - HyperLSTM</a></h4>\n": "<h4>\u2728 <a href=\"hypernetworks/hyper_lstm.html\">\u8d85\u7f51\u7edc-HyperLSTM</a></h4>\n",
 "<h4>\u2728 <a href=\"lora/index.html\">Low-Rank Adaptation (LoRA)</a></h4>\n": "<h4>\u2728 <a href=\"lora/index.html\">Low-Rank Adaptation (LoRA)</a></h4>\n",
 "<h4>\u2728 <a href=\"lstm/index.html\">LSTM</a></h4>\n": "<h4>\u2728 <a href=\"lstm/index.html\">LSTM</a></h4>\n",
 "<h4>\u2728 <a href=\"neox/index.html\">Eleuther GPT-NeoX</a></h4>\n": "<h4>\u2728 <a href=\"neox/index.html\">Eleuther GPT-neox</a></h4>\n",
 "<h4>\u2728 <a href=\"normalization/index.html\">Normalization Layers</a></h4>\n": "<h4>\u2728 <a href=\"normalization/index.html\">\u5f52\u4e00\u5316\u5c42</a></h4>\n",
 "<h4>\u2728 <a href=\"optimizers/index.html\">Optimizers</a></h4>\n": "<h4>\u2728 <a href=\"optimizers/index.html\">\u4f18\u5316\u5668</a></h4>\n",
 "<h4>\u2728 <a href=\"recurrent_highway_networks/index.html\">Recurrent Highway Networks</a></h4>\n": "<h4>\u2728 <a href=\"recurrent_highway_networks/index.html\">\u5faa\u73af\u9ad8\u901f\u8def\u7f51\u7edc</a></h4>\n",
 "<h4>\u2728 <a href=\"resnet/index.html\">ResNet</a></h4>\n": "<h4>\u2728 <a href=\"resnet/index.html\">ResNet</a></h4>\n",
 "<h4>\u2728 <a href=\"rl/index.html\">Reinforcement Learning</a></h4>\n": "<h4>\u2728 <a href=\"rl/index.html\">\u5f3a\u5316\u5b66\u4e60</a></h4>\n",
 "<h4>\u2728 <a href=\"sampling/index.html\">Language Model Sampling Techniques</a></h4>\n": "<h4>\u2728 <a href=\"sampling/index.html\">\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u6280\u672f</a></h4>\n",
 "<h4>\u2728 <a href=\"scaling/index.html\">Scalable Training/Inference</a></h4>\n": "<h4>\u2728 <a href=\"scaling/index.html\">\u53ef\u6269\u5c55\u8bad\u7ec3/\u63a8\u7406</a></h4>\n",
 "<h4>\u2728 <a href=\"sketch_rnn/index.html\">Sketch RNN</a></h4>\n": "<h4>\u2728 <a href=\"sketch_rnn/index.html\">Sketch RNN</a></h4>\n",
 "<h4>\u2728 <a href=\"transformers/index.html\">Transformers</a></h4>\n": "<h4>\u2728 <a href=\"transformers/index.html\">Transformers</a></h4>\n",
 "<h4>\u2728 <a href=\"uncertainty/index.html\">Uncertainty</a></h4>\n": "<h4>\u2728 <a href=\"uncertainty/index.html\">\u4e0d\u786e\u5b9a\u6027</a></h4>\n",
 "<h4>\u2728 <a href=\"unet/index.html\">U-Net</a></h4>\n": "<h4>\u2728 <a href=\"unet/index.html\">U-Net</a></h4>\n",
 "<h4>\u2728 Graph Neural Networks</h4>\n": "<h4>\u2728 \u56fe\u795e\u7ecf\u7f51\u7edc</h4>\n",
 "<p><span translate=no>_^_0_^_</span></p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p>Solving games with incomplete information such as poker with CFR.</p>\n": "<p>\u4f7f\u7528 CFR \u89e3\u51b3\u8bf8\u5982\u6251\u514b\u7b49\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f</p>\n",
 "<p>This is a collection of simple PyTorch implementations of neural networks and related algorithms. <a href=\"https://github.com/labmlai/annotated_deep_learning_paper_implementations\">These implementations</a> are documented with explanations, and the <a href=\"index.html\">website</a> renders these as side-by-side formatted notes. We believe these would help you understand these algorithms better.</p>\n": "<p>\u8fd9\u662f\u4e00\u4e2a\u7528 PyTorch \u5b9e\u73b0\u5404\u79cd\u795e\u7ecf\u7f51\u7edc\u548c\u76f8\u5173\u7b97\u6cd5\u7684\u96c6\u5408\u3002\u6bcf\u4e2a\u7b97\u6cd5\u7684<a href=\"https://github.com/labmlai/annotated_deep_learning_paper_implementations\">\u4ee3\u7801\u5b9e\u73b0</a>\u90fd\u6709\u8be6\u7ec6\u7684\u89e3\u91ca\u8bf4\u660e\uff0c\u4e14\u5728<a href=\"index.html\">\u7f51\u7ad9</a>\u4e0a\u4e0e\u4ee3\u7801\u9010\u884c\u5bf9\u5e94\u3002\u6211\u4eec\u76f8\u4fe1\uff0c\u8fd9\u4e9b\u5185\u5bb9\u5c06\u5e2e\u52a9\u60a8\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u7b97\u6cd5\u3002</p>\n",
 "<p>We are actively maintaining this repo and adding new implementations. <a href=\"https://twitter.com/labmlai\"><span translate=no>_^_0_^_</span></a> for updates.</p>\n": "<p>\u6211\u4eec\u6b63\u5728\u79ef\u6781\u7ef4\u62a4\u8fd9\u4e2a\u4ed3\u5e93\u5e76\u6dfb\u52a0\u65b0\u7684\u4ee3\u7801\u5b9e\u73b0\u3002<a href=\"https://twitter.com/labmlai\"><span translate=no>_^_0_^_</span></a>\u4ee5\u83b7\u53d6\u66f4\u65b0\u3002</p>\n",
 "<span translate=no>_^_0_^_</span>": "<span translate=no>_^_0_^_</span>",
 "<ul><li><a href=\"activations/fta/index.html\">Fuzzy Tiling Activations</a></li></ul>\n": "<ul><li><a href=\"activations/fta/index.html\">\u6a21\u7cca\u5e73\u94fa\u6fc0\u6d3b\u51fd\u6570</a></li></ul>\n",
 "<ul><li><a href=\"adaptive_computation/ponder_net/index.html\">PonderNet</a></li></ul>\n": "<ul><li><a href=\"adaptive_computation/ponder_net/index.html\">PonderNet</a></li></ul>\n",
 "<ul><li><a href=\"cfr/kuhn/index.html\">Kuhn Poker</a></li></ul>\n": "<ul><li><a href=\"cfr/kuhn/index.html\">\u5e93\u6069\u6251\u514b</a></li></ul>\n",
 "<ul><li><a href=\"diffusion/ddpm/index.html\">Denoising Diffusion Probabilistic Models (DDPM)</a> </li>\n<li><a href=\"diffusion/stable_diffusion/sampler/ddim.html\">Denoising Diffusion Implicit Models (DDIM)</a> </li>\n<li><a href=\"diffusion/stable_diffusion/latent_diffusion.html\">Latent Diffusion Models</a> </li>\n<li><a href=\"diffusion/stable_diffusion/index.html\">Stable Diffusion</a></li></ul>\n": "<ul><li><a href=\"diffusion/ddpm/index.html\">\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b (DDPM)</a></li>\n<li><a href=\"diffusion/stable_diffusion/sampler/ddim.html\">\u53bb\u566a\u6269\u6563\u9690\u5f0f\u6a21\u578b (DDIM)</a></li>\n<li><a href=\"diffusion/stable_diffusion/latent_diffusion.html\">\u6f5c\u5728\u6269\u6563\u6a21\u578b</a></li>\n<li><a href=\"diffusion/stable_diffusion/index.html\">Stable Diffusion</a></li></ul>\n",
 "<ul><li><a href=\"gan/original/index.html\">Original GAN</a> </li>\n<li><a href=\"gan/dcgan/index.html\">GAN with deep convolutional network</a> </li>\n<li><a href=\"gan/cycle_gan/index.html\">Cycle GAN</a> </li>\n<li><a href=\"gan/wasserstein/index.html\">Wasserstein GAN</a> </li>\n<li><a href=\"gan/wasserstein/gradient_penalty/index.html\">Wasserstein GAN with Gradient Penalty</a> </li>\n<li><a href=\"gan/stylegan/index.html\">StyleGAN 2</a></li></ul>\n": "<ul><li><a href=\"gan/original/index.html\">\u539f\u59cb GAN</a></li>\n<li><a href=\"gan/dcgan/index.html\">\u4f7f\u7528\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc\u7684 GAN</a></li>\n<li><a href=\"gan/cycle_gan/index.html\">\u5faa\u73af GAN</a></li>\n<li><a href=\"gan/wasserstein/index.html\">Wasserstein GAN</a></li>\n<li><a href=\"gan/wasserstein/gradient_penalty/index.html\">\u5177\u6709\u68af\u5ea6\u60e9\u7f5a\u7684 Wasserstein GAN</a></li>\n<li><a href=\"gan/stylegan/index.html\">StyleGan 2</a></li></ul>\n",
 "<ul><li><a href=\"graphs/gat/index.html\">Graph Attention Networks (GAT)</a> </li>\n<li><a href=\"graphs/gatv2/index.html\">Graph Attention Networks v2 (GATv2)</a></li></ul>\n": "<ul><li><a href=\"graphs/gat/index.html\">\u56fe\u6ce8\u610f\u529b\u7f51\u7edc (GAT)</a></li>\n<li><a href=\"graphs/gatv2/index.html\">\u56fe\u6ce8\u610f\u529b\u7f51\u7edc v2 (GATv2)</a></li></ul>\n",
 "<ul><li><a href=\"neox/samples/generate.html\">Generate on a 48GB GPU</a> </li>\n<li><a href=\"neox/samples/finetune.html\">Finetune on two 48GB GPUs</a> </li>\n<li><a href=\"neox/utils/llm_int8.html\">LLM.int8()</a></li></ul>\n": "<ul><li><a href=\"neox/samples/generate.html\">\u5728\u4e00\u5757 48GB GPU \u4e0a\u751f\u6210</a></li> \n<li><a href=\"neox/samples/finetune.html\">\u5728\u4e24\u5757 48GB GPU \u4e0a\u5fae\u8c03</a></li>\n<li><a href=\"neox/utils/llm_int8.html\">llm.int8 ()</a></li></ul>\n",
 "<ul><li><a href=\"normalization/batch_norm/index.html\">Batch Normalization</a> </li>\n<li><a href=\"normalization/layer_norm/index.html\">Layer Normalization</a> </li>\n<li><a href=\"normalization/instance_norm/index.html\">Instance Normalization</a> </li>\n<li><a href=\"normalization/group_norm/index.html\">Group Normalization</a> </li>\n<li><a href=\"normalization/weight_standardization/index.html\">Weight Standardization</a> </li>\n<li><a href=\"normalization/batch_channel_norm/index.html\">Batch-Channel Normalization</a> </li>\n<li><a href=\"normalization/deep_norm/index.html\">DeepNorm</a></li></ul>\n": "<ul><li><a href=\"normalization/batch_norm/index.html\">\u6279\u91cf\u5f52\u4e00\u5316</a></li>\n<li><a href=\"normalization/layer_norm/index.html\">\u5c42\u5f52\u4e00\u5316</a></li>\n<li><a href=\"normalization/instance_norm/index.html\">\u5b9e\u4f8b\u5f52\u4e00\u5316</a></li>\n<li><a href=\"normalization/group_norm/index.html\">\u7ec4\u5f52\u4e00\u5316</a></li>\n<li><a href=\"normalization/weight_standardization/index.html\">\u6743\u91cd\u6807\u51c6\u5316</a></li>\n<li><a href=\"normalization/batch_channel_norm/index.html\">\u6279-\u901a\u9053\u5f52\u4e00\u5316</a></li>\n<li><a href=\"normalization/deep_norm/index.html\">DeepNorm</a></li></ul>\n",
 "<ul><li><a href=\"optimizers/adam.html\">Adam</a> </li>\n<li><a href=\"optimizers/amsgrad.html\">AMSGrad</a> </li>\n<li><a href=\"optimizers/adam_warmup.html\">Adam Optimizer with warmup</a> </li>\n<li><a href=\"optimizers/noam.html\">Noam Optimizer</a> </li>\n<li><a href=\"optimizers/radam.html\">Rectified Adam Optimizer</a> </li>\n<li><a href=\"optimizers/ada_belief.html\">AdaBelief Optimizer</a> </li>\n<li><a href=\"optimizers/sophia.html\">Sophia-G Optimizer</a></li></ul>\n": "<ul><li><a href=\"optimizers/adam.html\">Adam \u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/amsgrad.html\">AMSGrad \u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/adam_warmup.html\">\u5177\u6709\u9884\u70ed\u7684 Adam \u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/noam.html\">Noam \u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/radam.html\">RAdam \u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/ada_belief.html\">AdaBelief \u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/sophia.html\">Sophia-G Optimizer</a></li></ul>\n",
 "<ul><li><a href=\"rl/ppo/index.html\">Proximal Policy Optimization</a> with  <a href=\"rl/ppo/gae.html\">Generalized Advantage Estimation</a> </li>\n<li><a href=\"rl/dqn/index.html\">Deep Q Networks</a> with  with <a href=\"rl/dqn/model.html\">Dueling Network</a>,  <a href=\"rl/dqn/replay_buffer.html\">Prioritized Replay</a>  and Double Q Network.</li></ul>\n": "<ul><li><a href=\"rl/ppo/index.html\">\u8fd1\u7aef\u7b56\u7565\u4f18\u5316</a>\u4e0e<a href=\"rl/ppo/gae.html\">\u5e7f\u4e49\u4f18\u52bf\u4f30\u8ba1</a></li>\n<li>\u5177\u6709<a href=\"rl/dqn/model.html\">\u5bf9\u6297\u7f51\u7edc</a>\u3001<a href=\"rl/dqn/replay_buffer.html\">\u4f18\u5148\u56de\u653e </a>\u548c\u53cc Q \u7f51\u7edc\u7684<a href=\"rl/dqn/index.html\">\u6df1\u5ea6 Q \u7f51\u7edc</a></li></ul>\n",
 "<ul><li><a href=\"sampling/greedy.html\">Greedy Sampling</a> </li>\n<li><a href=\"sampling/temperature.html\">Temperature Sampling</a> </li>\n<li><a href=\"sampling/top_k.html\">Top-k Sampling</a> </li>\n<li><a href=\"sampling/nucleus.html\">Nucleus Sampling</a></li></ul>\n": "<ul><li><a href=\"sampling/greedy.html\">\u8d2a\u5a6a\u91c7\u6837</a></li>\n<li><a href=\"sampling/temperature.html\">\u6e29\u5ea6\u91c7\u6837</a></li>\n<li><a href=\"sampling/top_k.html\">Top-K \u91c7\u6837</a></li>\n<li><a href=\"sampling/nucleus.html\">\u6838\u91c7\u6837</a></li></ul>\n",
 "<ul><li><a href=\"scaling/zero3/index.html\">Zero3 memory optimizations</a></li></ul>\n": "<ul><li><a href=\"scaling/zero3/index.html\">ZeRO-3 \u5185\u5b58\u4f18\u5316</a></li></ul>\n",
 "<ul><li><a href=\"transformers/mha.html\">Multi-headed attention</a> </li>\n<li><a href=\"transformers/models.html\">Transformer building blocks</a> </li>\n<li><a href=\"transformers/xl/index.html\">Transformer XL</a>  </li>\n<li><a href=\"transformers/xl/relative_mha.html\">Relative multi-headed attention</a> </li>\n<li><a href=\"transformers/rope/index.html\">Rotary Positional Embeddings (RoPE)</a> </li>\n<li><a href=\"transformers/alibi/index.html\">Attention with Linear Biases (ALiBi)</a> </li>\n<li><a href=\"transformers/retro/index.html\">RETRO</a> </li>\n<li><a href=\"transformers/compressive/index.html\">Compressive Transformer</a> </li>\n<li><a href=\"transformers/gpt/index.html\">GPT Architecture</a> </li>\n<li><a href=\"transformers/glu_variants/simple.html\">GLU Variants</a> </li>\n<li><a href=\"transformers/knn/index.html\">kNN-LM: Generalization through Memorization</a> </li>\n<li><a href=\"transformers/feedback/index.html\">Feedback Transformer</a> </li>\n<li><a href=\"transformers/switch/index.html\">Switch Transformer</a> </li>\n<li><a href=\"transformers/fast_weights/index.html\">Fast Weights Transformer</a> </li>\n<li><a href=\"transformers/fnet/index.html\">FNet</a> </li>\n<li><a href=\"transformers/aft/index.html\">Attention Free Transformer</a> </li>\n<li><a href=\"transformers/mlm/index.html\">Masked Language Model</a> </li>\n<li><a href=\"transformers/mlp_mixer/index.html\">MLP-Mixer: An all-MLP Architecture for Vision</a> </li>\n<li><a href=\"transformers/gmlp/index.html\">Pay Attention to MLPs (gMLP)</a> </li>\n<li><a href=\"transformers/vit/index.html\">Vision Transformer (ViT)</a> </li>\n<li><a href=\"transformers/primer_ez/index.html\">Primer EZ</a> </li>\n<li><a href=\"transformers/hour_glass/index.html\">Hourglass</a></li></ul>\n": "<ul><li><a href=\"transformers/mha.html\">\u591a\u5934\u6ce8\u610f\u529b</a></li>\n<li><a href=\"transformers/models.html\">Transformer \u6784\u5efa\u6a21\u5757</a></li>\n<li><a href=\"transformers/xl/index.html\">Transformer XL</a></li>\n<li><a href=\"transformers/xl/relative_mha.html\">\u76f8\u5bf9\u591a\u5934\u6ce8\u610f\u529b</a></li>\n<li><a href=\"transformers/rope/index.html\">\u65cb\u8f6c\u5f0f\u4f4d\u7f6e\u7f16\u7801 (ROPE)</a></li>\n<li><a href=\"transformers/alibi/index.html\">\u7ebf\u6027\u504f\u5dee\u6ce8\u610f\u529b (AliBI)</a></li>\n<li><a href=\"transformers/retro/index.html\">RETRO</a></li>\n<li><a href=\"transformers/compressive/index.html\">\u538b\u7f29 Transformer</a></li>\n<li><a href=\"transformers/gpt/index.html\">GPT \u67b6\u6784</a></li>\n<li><a href=\"transformers/glu_variants/simple.html\">GLU \u53d8\u4f53</a></li>\n<li><a href=\"transformers/knn/index.html\">kNN-LM\uff1a\u901a\u8fc7\u8bb0\u5fc6\u5b9e\u73b0\u6cdb\u5316</a></li>\n<li><a href=\"transformers/feedback/index.html\">\u81ea\u53cd\u9988 Transformer</a></li>\n<li><a href=\"transformers/switch/index.html\">Switch Transformer</a></li>\n<li><a href=\"transformers/fast_weights/index.html\">\u5feb\u901f\u6743\u91cd Transformer</a></li>\n<li><a href=\"transformers/fnet/index.html\">FNet</a></li>\n<li><a href=\"transformers/aft/index.html\">\u65e0\u6ce8\u610f\u529b Transformer</a></li>\n<li><a href=\"transformers/mlm/index.html\">\u63a9\u7801\u8bed\u8a00\u6a21\u578b</a></li>\n<li><a href=\"transformers/mlp_mixer/index.html\">MLP-Mixer\uff1a\u4e00\u79cd\u7528\u4e8e\u89c6\u89c9\u7684\u5168 MLP \u67b6\u6784</a></li>\n<li><a href=\"transformers/gmlp/index.html\">\u95e8\u63a7\u591a\u5c42\u611f\u77e5\u5668 (gMLP)</a></li>\n<li><a href=\"transformers/vit/index.html\">\u89c6\u89c9 Transformer (ViT)</a></li>\n<li><a href=\"transformers/primer_ez/index.html\">Primer</a></li>\n<li><a href=\"transformers/hour_glass/index.html\">\u6c99\u6f0f\u7f51\u7edc</a></li></ul>\n",
 "<ul><li><a href=\"uncertainty/evidence/index.html\">Evidential Deep Learning to Quantify Classification Uncertainty</a></li></ul>\n": "<ul><li><a href=\"uncertainty/evidence/index.html\">\u7528\u4e8e\u91cf\u5316\u5206\u7c7b\u4e0d\u786e\u5b9a\u6027\u7684\u8bc1\u636e\u6df1\u5ea6\u5b66\u4e60</a></li></ul>\n",
 "Annotated Research Paper Implementations: Transformers, StyleGAN, Stable Diffusion, DDPM/DDIM, LayerNorm, Nucleus Sampling and more": "labml.ai \u5e26\u6ce8\u91ca\u7684 PyTorch \u7248\u8bba\u6587\u5b9e\u73b0"
}